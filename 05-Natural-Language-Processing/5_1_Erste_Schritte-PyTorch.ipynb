{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2100fb7e8730c1f",
   "metadata": {},
   "source": [
    "# Erste Schritte mit Hugging Face\n",
    "<br>\n",
    "<a href=\"https://huggingface.co\"><img src=\"../img/huggingface_small.png\" width=\"30%\">\n",
    "<br>https://huggingface.co</a>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b012cf997fc198d",
   "metadata": {},
   "source": [
    "# Textklassifikation (Text Classification)\n",
    "\n",
    "Sprachmodelle sind in der Lage, Texte zu **klassifizieren**.\n",
    "\n",
    "Das bedeutet, dass das Ergebnis der Verarbeitung eines Textes die Aussage wie wahrscheinlich es ist, dass ein Text _positiv_ oder _negativ_ konnotiert ist. Diese Ausgabe ist also eine prozentuale Klassenzugehörigkeit zu den Klassen \"POSITIVE\" oder \"NEGATIVE\".\n",
    "\n",
    "\n",
    "---\n",
    "Beispiele angelehnt an\n",
    "\n",
    "Tunstall, Lewis; Werra, Leandro von; Wolf, Thomas (2023): Natural Language Processing mit Transformern. Sprachanwendungen mit Hugging Face erstellen. Heidelberg: O'Reilly (Animals). Online verfügbar unter https://nbn-resolving.org/urn:nbn:de:bsz:31-epflicht-2107005.     \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6d73ca22d6d9247d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:05:04.321635Z",
     "start_time": "2024-04-09T14:05:04.306004Z"
    }
   },
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime ac- tion figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\" \n",
    "# vgl. Tunstall et al. 2023, S. 10"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "b3e4942d7b182daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:05:09.331010Z",
     "start_time": "2024-04-09T14:05:05.177165Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "14ef9d1c5ef81073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:05:09.713546Z",
     "start_time": "2024-04-09T14:05:09.331010Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "outputs = classifier(text) \n",
    "pd.DataFrame(outputs)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      label    score\n",
       "0  NEGATIVE  0.87243"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.87243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "ff4036639521e524",
   "metadata": {},
   "source": [
    "# Erkennung von Namens-Entitäten (Named Entity Recognition)\n",
    "\n",
    "Sprachmodelle sind in der Lage, Produkte, Orte oder Eigennamen aus Texten zu extrahieren. Diese werden als \"Named Entity\" bezeichnet."
   ]
  },
  {
   "cell_type": "code",
   "id": "9a04f1ac1ddda1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:05:14.325350Z",
     "start_time": "2024-04-09T14:05:12.837806Z"
    }
   },
   "source": [
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "outputs = ner_tagger(text)\n",
    "pd.DataFrame(outputs)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  entity_group     score           word  start  end\n",
       "0          ORG  0.855356         Amazon      5   11\n",
       "1         MISC  0.992322  Optimus Prime     36   49\n",
       "2          LOC  0.999735        Germany     92   99\n",
       "3         MISC  0.606780           Mega    210  214\n",
       "4          PER  0.524000         ##tron    214  218\n",
       "5          ORG  0.630277         Decept    255  261\n",
       "6         MISC  0.506672        ##icons    261  266\n",
       "7         MISC  0.772444       Megatron    352  360\n",
       "8         MISC  0.988840  Optimus Prime    369  382\n",
       "9          PER  0.814836      Bumblebee    504  513"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.855356</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.992322</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>Germany</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.606780</td>\n",
       "      <td>Mega</td>\n",
       "      <td>210</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>##tron</td>\n",
       "      <td>214</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.630277</td>\n",
       "      <td>Decept</td>\n",
       "      <td>255</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.506672</td>\n",
       "      <td>##icons</td>\n",
       "      <td>261</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.772444</td>\n",
       "      <td>Megatron</td>\n",
       "      <td>352</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.988840</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>369</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.814836</td>\n",
       "      <td>Bumblebee</td>\n",
       "      <td>504</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "cf1ead8c672db5cd",
   "metadata": {},
   "source": [
    "Auch hier ist das Ergebnis eine statistische Zuordnung von Wörtern zu Kategorien mit der Angabe von Wahrscheinlichkeiten, die die so genannte \"confidence\" des Modells angeben. Dies ist die \"Sicherheit\" mit der das Modell die Zuordnung einschätzt. Kategorien sind z.B. \"Organisation (ORG)\", \"Location (LOC)\" oder \"Person (PER)\".\n",
    "\n",
    "Zusätzlich gibt das Modell einen Bereich an, in dem es das Wort (oder die Wortgruppe) gefunden hat.\n",
    "\n",
    "In der Ausgabe können sich auch noch Tokens (mit ## gekennzeichnet) befinden, wenn kein ganzes Wort oder eine Wortgruppe einer Kategorie zugeordnet werden konnte. Interessant ist hier, dass letztlich das \"Plural-Token\" separat behandelt wurde (##ns stammt aus dem Wort \"Decepticons\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d83b301e2e101",
   "metadata": {},
   "source": [
    "# Beantwortung von Fragen (Question Answering)\n",
    "\n",
    "Sprachmodelle können Fragen beantworten. Dies setzt natürlich voraus, dass das Modell einen Kontext kennt zu dem Fragen beantwortet werden sollen.\n",
    "Hier wollen wir eine Frage zum obigen Text beantworten, der dem Modell bereits bekannt ist. Wir wollen folgende Frage stellen:\n",
    "\n",
    "**What does the customer want?**"
   ]
  },
  {
   "cell_type": "code",
   "id": "96900bd57d9e70a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:05:18.478115Z",
     "start_time": "2024-04-09T14:05:17.157434Z"
    }
   },
   "source": [
    "reader = pipeline(\"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\")\n",
    "question = \"What does the customer want?\"\n",
    "outputs = reader(question=question, context=text)\n",
    "pd.DataFrame([outputs])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      score  start  end                   answer\n",
       "0  0.533085    337  360  an exchange of Megatron"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.533085</td>\n",
       "      <td>337</td>\n",
       "      <td>360</td>\n",
       "      <td>an exchange of Megatron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "ee3cd6d076c3d9c2",
   "metadata": {},
   "source": [
    "Auch hier wird zusätzlich zur Antwort ein Score ausgegeben, der die confidence des Modells angibt.\n",
    "<blockquote>Beachten Sie: \n",
    "\n",
    "Es handelt sich hier nicht um einen generativen Ansatz, sondern letztlich auch um eine Text-Klassifizierung. Das Ergebnis des Modells ist eine Textstelle, in der das Modell die Antwort vermutet. Es handelt sich bei diesem Ansatz um so genanntes **\"Extractive Question Answering\"**. Hierfür gibt das Modell die Spann mit \"start\" und \"end\" aus, in dem es die Antwort vermutet.</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89592d55b0578fb1",
   "metadata": {},
   "source": [
    "# Textzusammenfassung (Summarization)\n",
    "\n",
    "Sprachmodelle sind in der Lage, Texte zusammenzufassen. Hierfür gibt es verschiedene methodische Ansätze. Zunäschst wollen wir nur ein einführendes Beispiel betrachten."
   ]
  },
  {
   "cell_type": "code",
   "id": "102013e9d971bfc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:05:27.087600Z",
     "start_time": "2024-04-09T14:05:21.353400Z"
    }
   },
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(text, max_length=150, min_length=40, do_sample=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but your input_length is only 113. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=56)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "145b5691f076efe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:05:28.053954Z",
     "start_time": "2024-04-09T14:05:28.040947Z"
    }
   },
   "source": [
    "summary[0]['summary_text']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bumblebee ordered an Optimus Prime figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I hope you can understand my dilemma.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "26a1608c5eb0d84f",
   "metadata": {},
   "source": [
    "Auffällig sind am Ergebnis zwei Punkte:\n",
    "- Das Modell hat erkannt, dass der Autor \"Bumblebee\" ist.\n",
    "- Ansonsten sind im Ergebnis letztlich Textbestandteile zusammenkopiert.\n",
    "- Der eigentliche Wunsch auf \"Austausch\" der Figur wurde nicht in der Zusammenfassung erwähnt.\n",
    "\n",
    "Weiterführende Anleitung bei Keras: https://keras.io/examples/nlp/t5_hf_summarization/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164a956c7a44840",
   "metadata": {},
   "source": [
    "# Übersetzen\n",
    "[Credits to: https://huggingface.co/docs/transformers/task_summary]"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0320886b608c99b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:05:34.040676Z",
     "start_time": "2024-04-09T14:05:33.279705Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text = \"translate English to French: Hugging Face is a community-based open-source platform for machine learning.\"\n",
    "translator = pipeline(task=\"translation\", model=\"google-t5/t5-small\", max_length=400)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thomase\\miniconda3\\envs\\studientage-pytorch\\lib\\site-packages\\transformers\\pipelines\\__init__.py:1086: UserWarning: \"translation\" task was used, instead of \"translation_XX_to_YY\", defaulting to \"translation_en_to_de\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "426f53c6c489f4c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:05:58.641469Z",
     "start_time": "2024-04-09T14:05:58.228098Z"
    }
   },
   "source": [
    "translator(text)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"Hugging Face est une tribune communautaire de l'apprentissage des machines.\"}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "5accfb3ae6d05532",
   "metadata": {},
   "source": [
    "# Text-Generierung"
   ]
  },
  {
   "cell_type": "code",
   "id": "2ac3651712fbdd72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:06:01.272709Z",
     "start_time": "2024-04-09T14:05:59.446981Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "prompt = \"What is machine learning?\"\n",
    "generator = pipeline(task=\"text-generation\", model=\"openai-community/gpt2\")\n",
    "result = generator(prompt)  # doctest: +SKIP"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "6c4110d3a1dfa623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T14:06:03.114794Z",
     "start_time": "2024-04-09T14:06:03.098733Z"
    }
   },
   "source": [
    "result[0]['generated_text']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is machine learning?\\n\\nMachine learning (or ML, to be more precise) is a statistical programming language which uses code analysis and algorithms to identify tasks, predict outcomes or learn how to perform them. It has always been a field that has'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "1d83d5a978adcdb6",
   "metadata": {},
   "source": [
    "# Fazit\n",
    "\n",
    "Wir konnten sehen, dass bereits mit dem direkten Einsatz vortrainierter Modell größtenteils brauchbare Ergebnisse erzielt werden können.\n",
    "Um nun tatsächlich gute Ergebnisse zu erzielen werden wir tiefer eintauchen.  "
   ]
  },
  {
   "cell_type": "code",
   "id": "d6375b23cd382774",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
