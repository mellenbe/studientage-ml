{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2100fb7e8730c1f",
   "metadata": {},
   "source": [
    "# Erste Schritte mit Hugging Face\n",
    "<br>\n",
    "<a href=\"https://huggingface.co\"><img src=\"../img/huggingface_small.png\" width=\"30%\">\n",
    "<br>https://huggingface.co</a>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b012cf997fc198d",
   "metadata": {},
   "source": [
    "# Textklassifikation (Text Classification)\n",
    "\n",
    "Sprachmodelle sind in der Lage, Texte zu **klassifizieren**.\n",
    "\n",
    "Das bedeutet, dass das Ergebnis der Verarbeitung eines Textes die Aussage wie wahrscheinlich es ist, dass ein Text _positiv_ oder _negativ_ konnotiert ist. Diese Ausgabe ist also eine prozentuale Klassenzugehörigkeit zu den Klassen \"POSITIVE\" oder \"NEGATIVE\".\n",
    "\n",
    "\n",
    "---\n",
    "Beispiele angelehnt an\n",
    "\n",
    "Tunstall, Lewis; Werra, Leandro von; Wolf, Thomas (2023): Natural Language Processing mit Transformern. Sprachanwendungen mit Hugging Face erstellen. Heidelberg: O'Reilly (Animals). Online verfügbar unter https://nbn-resolving.org/urn:nbn:de:bsz:31-epflicht-2107005.     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7564d3d242a927f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:32:02.555001Z",
     "start_time": "2024-04-12T11:31:59.493537Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73ca22d6d9247d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:32:07.045572Z",
     "start_time": "2024-04-12T11:32:07.035211Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime ac- tion figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\" \n",
    "# vgl. Tunstall et al. 2023, S. 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4942d7b182daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:32:45.984767Z",
     "start_time": "2024-04-12T11:32:42.535309Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef9d1c5ef81073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:33:32.950170Z",
     "start_time": "2024-04-12T11:33:31.766639Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "outputs = classifier(text) \n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4036639521e524",
   "metadata": {},
   "source": [
    "# Erkennung von Namens-Entitäten (Named Entity Recognition)\n",
    "\n",
    "Sprachmodelle sind in der Lage, Produkte, Orte oder Eigennamen aus Texten zu extrahieren. Diese werden als \"Named Entity\" bezeichnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04f1ac1ddda1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:37:18.685390Z",
     "start_time": "2024-04-12T11:37:16.157111Z"
    }
   },
   "outputs": [],
   "source": [
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "outputs = ner_tagger(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ead8c672db5cd",
   "metadata": {},
   "source": [
    "Auch hier ist das Ergebnis eine statistische Zuordnung von Wörtern zu Kategorien mit der Angabe von Wahrscheinlichkeiten, die die so genannte \"confidence\" des Modells angeben. Dies ist die \"Sicherheit\" mit der das Modell die Zuordnung einschätzt. Kategorien sind z.B. \"Organisation (ORG)\", \"Location (LOC)\" oder \"Person (PER)\".\n",
    "\n",
    "Zusätzlich gibt das Modell einen Bereich an, in dem es das Wort (oder die Wortgruppe) gefunden hat.\n",
    "\n",
    "In der Ausgabe können sich auch noch Tokens (mit ## gekennzeichnet) befinden, wenn kein ganzes Wort oder eine Wortgruppe einer Kategorie zugeordnet werden konnte. Interessant ist hier, dass letztlich das \"Plural-Token\" separat behandelt wurde (##ns stammt aus dem Wort \"Decepticons\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d83b301e2e101",
   "metadata": {},
   "source": [
    "# Beantwortung von Fragen (Question Answering)\n",
    "\n",
    "Sprachmodelle können Fragen beantworten. Dies setzt natürlich voraus, dass das Modell einen Kontext kennt zu dem Fragen beantwortet werden sollen.\n",
    "Hier wollen wir eine Frage zum obigen Text beantworten, der dem Modell bereits bekannt ist. Wir wollen folgende Frage stellen:\n",
    "\n",
    "**What does the customer want?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96900bd57d9e70a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:39:47.083905Z",
     "start_time": "2024-04-12T11:39:45.972886Z"
    }
   },
   "outputs": [],
   "source": [
    "reader = pipeline(\"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\")\n",
    "question = \"What does the customer want?\"\n",
    "outputs = reader(question=question, context=text)\n",
    "pd.DataFrame([outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3cd6d076c3d9c2",
   "metadata": {},
   "source": [
    "Auch hier wird zusätzlich zur Antwort ein Score ausgegeben, der die confidence des Modells angibt.\n",
    "<blockquote>Beachten Sie: \n",
    "\n",
    "Es handelt sich hier nicht um einen generativen Ansatz, sondern letztlich auch um eine Text-Klassifizierung. Das Ergebnis des Modells ist eine Textstelle, in der das Modell die Antwort vermutet. Es handelt sich bei diesem Ansatz um so genanntes **\"Extractive Question Answering\"**. Hierfür gibt das Modell die Spann mit \"start\" und \"end\" aus, in dem es die Antwort vermutet.</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89592d55b0578fb1",
   "metadata": {},
   "source": [
    "# Textzusammenfassung (Summarization)\n",
    "\n",
    "Sprachmodelle sind in der Lage, Texte zusammenzufassen. Hierfür gibt es verschiedene methodische Ansätze. Zunäschst wollen wir nur ein einführendes Beispiel betrachten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102013e9d971bfc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:41:04.411186Z",
     "start_time": "2024-04-12T11:40:55.766133Z"
    }
   },
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(text, max_length=150, min_length=40, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b5691f076efe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:41:36.721498Z",
     "start_time": "2024-04-12T11:41:36.690216Z"
    }
   },
   "outputs": [],
   "source": [
    "summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a1608c5eb0d84f",
   "metadata": {},
   "source": [
    "Auffällig sind am Ergebnis zwei Punkte:\n",
    "- Das Modell hat erkannt, dass der Autor \"Bumblebee\" ist.\n",
    "- Ansonsten sind im Ergebnis letztlich Textbestandteile zusammenkopiert.\n",
    "- Der eigentliche Wunsch auf \"Austausch\" der Figur wurde nicht in der Zusammenfassung erwähnt.\n",
    "\n",
    "Weiterführende Anleitung bei Keras: https://keras.io/examples/nlp/t5_hf_summarization/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164a956c7a44840",
   "metadata": {},
   "source": [
    "# Übersetzen\n",
    "[Credits to: https://huggingface.co/docs/transformers/task_summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0320886b608c99b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:42:55.318609Z",
     "start_time": "2024-04-12T11:42:52.630216Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text = \"translate English to French: Hugging Face is a community-based open-source platform for machine learning.\"\n",
    "translator = pipeline(task=\"translation\", model=\"google-t5/t5-small\", max_length=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f53c6c489f4c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T18:20:33.810045Z",
     "start_time": "2024-04-11T18:20:33.025136Z"
    }
   },
   "outputs": [],
   "source": [
    "translator(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5accfb3ae6d05532",
   "metadata": {},
   "source": [
    "# Text-Generierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac3651712fbdd72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:44:29.267946Z",
     "start_time": "2024-04-12T11:44:25.969741Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "prompt = \"What is machine learning?\"\n",
    "generator = pipeline(task=\"text-generation\", model=\"openai-community/gpt2\")\n",
    "result = generator(prompt)  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4110d3a1dfa623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:44:29.993279Z",
     "start_time": "2024-04-12T11:44:29.977628Z"
    }
   },
   "outputs": [],
   "source": [
    "result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83d5a978adcdb6",
   "metadata": {},
   "source": [
    "# Fazit\n",
    "\n",
    "Wir konnten sehen, dass bereits mit dem direkten Einsatz vortrainierter Modell größtenteils brauchbare Ergebnisse erzielt werden können.\n",
    "Um nun tatsächlich gute Ergebnisse zu erzielen werden wir tiefer eintauchen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6375b23cd382774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T18:20:36.918819Z",
     "start_time": "2024-04-11T18:20:36.903133Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
