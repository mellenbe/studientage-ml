{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2100fb7e8730c1f",
   "metadata": {},
   "source": [
    "# Erste Schritte mit Hugging Face\n",
    "<br>\n",
    "<a href=\"https://huggingface.co\"><img src=\"../img/huggingface_small.png\" width=\"30%\">\n",
    "<br>https://huggingface.co</a>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b012cf997fc198d",
   "metadata": {},
   "source": [
    "# Textklassifikation (Text Classification)\n",
    "\n",
    "Sprachmodelle sind in der Lage, Texte zu **klassifizieren**.\n",
    "\n",
    "Das bedeutet, dass das Ergebnis der Verarbeitung eines Textes die Aussage wie wahrscheinlich es ist, dass ein Text _positiv_ oder _negativ_ konnotiert ist. Diese Ausgabe ist also eine prozentuale Klassenzugehörigkeit zu den Klassen \"POSITIVE\" oder \"NEGATIVE\".\n",
    "\n",
    "\n",
    "---\n",
    "Beispiele angelehnt an\n",
    "\n",
    "Tunstall, Lewis; Werra, Leandro von; Wolf, Thomas (2023): Natural Language Processing mit Transformern. Sprachanwendungen mit Hugging Face erstellen. Heidelberg: O'Reilly (Animals). Online verfügbar unter https://nbn-resolving.org/urn:nbn:de:bsz:31-epflicht-2107005.     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3607f87-8abc-43e1-bb6c-f375638fe4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 12.4\n",
      "ID of current CUDA device: 0\n",
      "Name of current CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    " \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "       \n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d73ca22d6d9247d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:32:07.045572Z",
     "start_time": "2024-04-12T11:32:07.035211Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime ac- tion figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\" \n",
    "# vgl. Tunstall et al. 2023, S. 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3e4942d7b182daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:32:45.984767Z",
     "start_time": "2024-04-12T11:32:42.535309Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "if torch.cuda.is_available():\n",
    "    classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=0)\n",
    "else:\n",
    "    classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ef9d1c5ef81073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:33:32.950170Z",
     "start_time": "2024-04-12T11:33:31.766639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.87243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label    score\n",
       "0  NEGATIVE  0.87243"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "outputs = classifier(text) \n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4036639521e524",
   "metadata": {},
   "source": [
    "# Erkennung von Namens-Entitäten (Named Entity Recognition)\n",
    "\n",
    "Sprachmodelle sind in der Lage, Produkte, Orte oder Eigennamen aus Texten zu extrahieren. Diese werden als \"Named Entity\" bezeichnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a04f1ac1ddda1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:37:18.685390Z",
     "start_time": "2024-04-12T11:37:16.157111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.855355</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.992322</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>Germany</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.606777</td>\n",
       "      <td>Mega</td>\n",
       "      <td>210</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.524002</td>\n",
       "      <td>##tron</td>\n",
       "      <td>214</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.630277</td>\n",
       "      <td>Decept</td>\n",
       "      <td>255</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.506673</td>\n",
       "      <td>##icons</td>\n",
       "      <td>261</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.772442</td>\n",
       "      <td>Megatron</td>\n",
       "      <td>352</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.988840</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>369</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.814836</td>\n",
       "      <td>Bumblebee</td>\n",
       "      <td>504</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score           word  start  end\n",
       "0          ORG  0.855355         Amazon      5   11\n",
       "1         MISC  0.992322  Optimus Prime     36   49\n",
       "2          LOC  0.999735        Germany     92   99\n",
       "3         MISC  0.606777           Mega    210  214\n",
       "4          PER  0.524002         ##tron    214  218\n",
       "5          ORG  0.630277         Decept    255  261\n",
       "6         MISC  0.506673        ##icons    261  266\n",
       "7         MISC  0.772442       Megatron    352  360\n",
       "8         MISC  0.988840  Optimus Prime    369  382\n",
       "9          PER  0.814836      Bumblebee    504  513"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", device=0)\n",
    "else:\n",
    "    ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "outputs = ner_tagger(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ead8c672db5cd",
   "metadata": {},
   "source": [
    "Auch hier ist das Ergebnis eine statistische Zuordnung von Wörtern zu Kategorien mit der Angabe von Wahrscheinlichkeiten, die die so genannte \"confidence\" des Modells angeben. Dies ist die \"Sicherheit\" mit der das Modell die Zuordnung einschätzt. Kategorien sind z.B. \"Organisation (ORG)\", \"Location (LOC)\" oder \"Person (PER)\".\n",
    "\n",
    "Zusätzlich gibt das Modell einen Bereich an, in dem es das Wort (oder die Wortgruppe) gefunden hat.\n",
    "\n",
    "In der Ausgabe können sich auch noch Tokens (mit ## gekennzeichnet) befinden, wenn kein ganzes Wort oder eine Wortgruppe einer Kategorie zugeordnet werden konnte. Interessant ist hier, dass letztlich das \"Plural-Token\" separat behandelt wurde (##ns stammt aus dem Wort \"Decepticons\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0d83b301e2e101",
   "metadata": {},
   "source": [
    "# Beantwortung von Fragen (Question Answering)\n",
    "\n",
    "Sprachmodelle können Fragen beantworten. Dies setzt natürlich voraus, dass das Modell einen Kontext kennt zu dem Fragen beantwortet werden sollen.\n",
    "Hier wollen wir eine Frage zum obigen Text beantworten, der dem Modell bereits bekannt ist. Wir wollen folgende Frage stellen:\n",
    "\n",
    "**What does the customer want?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96900bd57d9e70a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:39:47.083905Z",
     "start_time": "2024-04-12T11:39:45.972886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.533085</td>\n",
       "      <td>337</td>\n",
       "      <td>360</td>\n",
       "      <td>an exchange of Megatron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start  end                   answer\n",
       "0  0.533085    337  360  an exchange of Megatron"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    reader = pipeline(\"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\", device=0)\n",
    "else:\n",
    "    reader = pipeline(\"question-answering\", model=\"distilbert/distilbert-base-cased-distilled-squad\")\n",
    "question = \"What does the customer want?\"\n",
    "outputs = reader(question=question, context=text)\n",
    "pd.DataFrame([outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3cd6d076c3d9c2",
   "metadata": {},
   "source": [
    "Auch hier wird zusätzlich zur Antwort ein Score ausgegeben, der die confidence des Modells angibt.\n",
    "<blockquote>Beachten Sie: \n",
    "\n",
    "Es handelt sich hier nicht um einen generativen Ansatz, sondern letztlich auch um eine Text-Klassifizierung. Das Ergebnis des Modells ist eine Textstelle, in der das Modell die Antwort vermutet. Es handelt sich bei diesem Ansatz um so genanntes **\"Extractive Question Answering\"**. Hierfür gibt das Modell die Spann mit \"start\" und \"end\" aus, in dem es die Antwort vermutet.</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89592d55b0578fb1",
   "metadata": {},
   "source": [
    "# Textzusammenfassung (Summarization)\n",
    "\n",
    "Sprachmodelle sind in der Lage, Texte zusammenzufassen. Hierfür gibt es verschiedene methodische Ansätze. Zunäschst wollen wir nur ein einführendes Beispiel betrachten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "102013e9d971bfc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:41:04.411186Z",
     "start_time": "2024-04-12T11:40:55.766133Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0)\n",
    "else:\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(text, max_length=110, min_length=40, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "145b5691f076efe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:41:36.721498Z",
     "start_time": "2024-04-12T11:41:36.690216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bumblebee ordered an Optimus Prime figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead. As a lifelong enemy of the Decepticons, I hope you can understand my dilemma.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a1608c5eb0d84f",
   "metadata": {},
   "source": [
    "Auffällig sind am Ergebnis zwei Punkte:\n",
    "- Das Modell hat erkannt, dass der Autor \"Bumblebee\" ist.\n",
    "- Ansonsten sind im Ergebnis letztlich Textbestandteile zusammenkopiert.\n",
    "- Der eigentliche Wunsch auf \"Austausch\" der Figur wurde nicht in der Zusammenfassung erwähnt.\n",
    "\n",
    "Weiterführende Anleitung bei Keras: https://keras.io/examples/nlp/t5_hf_summarization/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164a956c7a44840",
   "metadata": {},
   "source": [
    "# Übersetzen\n",
    "[Credits to: https://huggingface.co/docs/transformers/task_summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0320886b608c99b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:42:55.318609Z",
     "start_time": "2024-04-12T11:42:52.630216Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text = \"translate English to French: Hugging Face is a community-based open-source platform for machine learning.\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    translator = pipeline(task=\"translation\", model=\"google-t5/t5-small\", max_length=400, device=0)\n",
    "else:\n",
    "    translator = pipeline(task=\"translation\", model=\"google-t5/t5-small\", max_length=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "426f53c6c489f4c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T18:20:33.810045Z",
     "start_time": "2024-04-11T18:20:33.025136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': \"Hugging Face est une tribune communautaire de l'apprentissage des machines.\"}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5accfb3ae6d05532",
   "metadata": {},
   "source": [
    "# Text-Generierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ac3651712fbdd72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:44:29.267946Z",
     "start_time": "2024-04-12T11:44:25.969741Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "prompt = \"What is machine learning?\"\n",
    "if torch.cuda.is_available():\n",
    "    generator = pipeline(task=\"text-generation\", model=\"openai-community/gpt2\", device=0)\n",
    "else:\n",
    "    generator = pipeline(task=\"text-generation\", model=\"openai-community/gpt2\")\n",
    "\n",
    "result = generator(prompt)  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c4110d3a1dfa623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:44:29.993279Z",
     "start_time": "2024-04-12T11:44:29.977628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is machine learning?\\n\\nMachine learning is a new field that uses the techniques of deep neural networks to discover and predict the shape or function of things in a digital grid. In order to model or visualize an activity, a computer creates a graph'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83d5a978adcdb6",
   "metadata": {},
   "source": [
    "# Fazit\n",
    "\n",
    "Wir konnten sehen, dass bereits mit dem direkten Einsatz vortrainierter Modell größtenteils brauchbare Ergebnisse erzielt werden können.\n",
    "Um nun tatsächlich gute Ergebnisse zu erzielen werden wir tiefer eintauchen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6375b23cd382774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T18:20:36.918819Z",
     "start_time": "2024-04-11T18:20:36.903133Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
