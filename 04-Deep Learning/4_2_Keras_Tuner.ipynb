{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13fc175e968dd432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:45:30.563606Z",
     "start_time": "2024-04-04T19:45:30.548153Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#import some necessary librairies\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "warnings.warn_explicit = ignore_warn\n",
    "\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, History, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.metrics import RootMeanSquaredError, MeanSquaredError\n",
    "from matplotlib import pyplot as plt\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617701f-cd24-41fc-94d3-cb335db19394",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Daten aus vorigem Schritt laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70474c85-f1e2-426c-ac1d-a0f2aee1df95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:45:33.140749Z",
     "start_time": "2024-04-04T19:45:33.132184Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/house-prices-advanced-regression-techniques/x_preprocessed_train.pkl', 'rb') as handle:\n",
    "    X_preprocessed_train = pickle.load(handle)\n",
    "\n",
    "with open('../data/house-prices-advanced-regression-techniques/y_train.pkl', 'rb') as handle:\n",
    "    y_preprocessed_train = pickle.load(handle)\n",
    "    \n",
    "with open('../data/house-prices-advanced-regression-techniques/x_test.pkl', 'rb') as handle:\n",
    "    X_preprocessed_test = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fc1e5-0943-479a-a1a8-ff918f1df5aa",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81bd49a-085b-47ca-b842-8fb84925dcd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-04T19:45:37.720946Z",
     "start_time": "2024-04-04T19:45:37.533645Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 4354 # Random_state ist ein seed, damit gegebenenfalls immer mit der selben pseudo Random Folge gearbeitet wird.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed_train, y_preprocessed_train, test_size=0.2, random_state=seed) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6415661-c68b-4183-88e5-53b1dec89673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperParameters as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed22bb22-303b-4585-b50b-478a3148de5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    # The Input Layer :\n",
    "    model.add(Dense(hp.Choice('units1', [32, 64, 128, 256]), kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "    \n",
    "    # The Hidden Layers :\n",
    "    model.add(Dense(hp.Choice('units2', [32, 64, 128, 256, 1024]), kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(hp.Choice('units3', [32, 64, 128, 256, 1024]), kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(hp.Choice('units4', [32, 64, 128, 256, 1024]), kernel_initializer='normal',activation='relu'))    \n",
    "    # The Output Layer :\n",
    "    model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # Compile the network :\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=hp_learning_rate), metrics=[MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "470f0f9b-1214-44a7-880d-07d2a4f08e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from tuner_dir\\tune deep house prices\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='mean_squared_error',\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='tuner_dir',\n",
    "                     project_name='tune deep house prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343a9315-50ea-4476-af16-9ae0e194d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "268130a9-0fcd-4d78-b7c8-1533518c32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e874fc4a-36a1-4fd8-b496-bf6e22e29f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete.\n",
      "The optimal number of units in the first densely-connected layer is 64.\n",
      "The optimal number of units in the second densely-connected layer is 128.\n",
      "The optimal number of units in the third densely-connected layer is 64.\n",
      "The optimal number of units in the fourth densely-connected layer is 1024.\n",
      "The optimal learning_rate for Adam is 0.01.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete.\n",
    "The optimal number of units in the first densely-connected layer is {best_hps.get('units1')}.\n",
    "The optimal number of units in the second densely-connected layer is {best_hps.get('units2')}.\n",
    "The optimal number of units in the third densely-connected layer is {best_hps.get('units3')}.\n",
    "The optimal number of units in the fourth densely-connected layer is {best_hps.get('units4')}.\n",
    "The optimal learning_rate for Adam is {best_hps.get('learning_rate')}.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a6c8598-5da3-4093-8de3-6ac9a5baf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f16804-f734-43c6-8885-345f75316974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint_name = 'model.weights.best.hdf5'\n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "history = History()\n",
    "callbacks_list = [checkpoint, history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d04054-d59e-464f-b8b4-56d039a35c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/30 [>.............................] - ETA: 8s - loss: 146.7842 - mean_squared_error: 146.7842\n",
      "Epoch 1: val_loss improved from inf to 6.42915, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 1s 8ms/step - loss: 78.1562 - mean_squared_error: 78.1562 - val_loss: 6.4292 - val_mean_squared_error: 6.4292\n",
      "Epoch 2/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 5.5891 - mean_squared_error: 5.5891\n",
      "Epoch 2: val_loss improved from 6.42915 to 0.74799, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 2.6343 - mean_squared_error: 2.6343 - val_loss: 0.7480 - val_mean_squared_error: 0.7480\n",
      "Epoch 3/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.7507 - mean_squared_error: 0.7507\n",
      "Epoch 3: val_loss improved from 0.74799 to 0.18469, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2671 - mean_squared_error: 0.2671 - val_loss: 0.1847 - val_mean_squared_error: 0.1847\n",
      "Epoch 4/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0999 - mean_squared_error: 0.0999\n",
      "Epoch 4: val_loss improved from 0.18469 to 0.10855, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1040 - mean_squared_error: 0.1040 - val_loss: 0.1086 - val_mean_squared_error: 0.1086\n",
      "Epoch 5/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0416 - mean_squared_error: 0.0416\n",
      "Epoch 5: val_loss improved from 0.10855 to 0.08880, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0754 - mean_squared_error: 0.0754 - val_loss: 0.0888 - val_mean_squared_error: 0.0888\n",
      "Epoch 6/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0438 - mean_squared_error: 0.0438\n",
      "Epoch 6: val_loss improved from 0.08880 to 0.06760, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0424 - mean_squared_error: 0.0424 - val_loss: 0.0676 - val_mean_squared_error: 0.0676\n",
      "Epoch 7/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "Epoch 7: val_loss improved from 0.06760 to 0.06167, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0617 - val_mean_squared_error: 0.0617\n",
      "Epoch 8/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0262 - mean_squared_error: 0.0262\n",
      "Epoch 8: val_loss improved from 0.06167 to 0.05718, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0572 - val_mean_squared_error: 0.0572\n",
      "Epoch 9/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0193\n",
      "Epoch 9: val_loss improved from 0.05718 to 0.05338, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0534 - val_mean_squared_error: 0.0534\n",
      "Epoch 10/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0190 - mean_squared_error: 0.0190\n",
      "Epoch 10: val_loss improved from 0.05338 to 0.04608, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
      "Epoch 11/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127\n",
      "Epoch 11: val_loss did not improve from 0.04608\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
      "Epoch 12/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0155 - mean_squared_error: 0.0155\n",
      "Epoch 12: val_loss improved from 0.04608 to 0.04295, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
      "Epoch 13/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126\n",
      "Epoch 13: val_loss did not improve from 0.04295\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0436 - val_mean_squared_error: 0.0436\n",
      "Epoch 14/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "Epoch 14: val_loss improved from 0.04295 to 0.04198, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
      "Epoch 15/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 15: val_loss improved from 0.04198 to 0.04047, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0405 - val_mean_squared_error: 0.0405\n",
      "Epoch 16/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
      "Epoch 16: val_loss did not improve from 0.04047\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
      "Epoch 17/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0136 - mean_squared_error: 0.0136\n",
      "Epoch 17: val_loss did not improve from 0.04047\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0495 - val_mean_squared_error: 0.0495\n",
      "Epoch 18/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0399 - mean_squared_error: 0.0399\n",
      "Epoch 18: val_loss did not improve from 0.04047\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
      "Epoch 19/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0260 - mean_squared_error: 0.0260\n",
      "Epoch 19: val_loss improved from 0.04047 to 0.03707, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
      "Epoch 20/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0127 - mean_squared_error: 0.0127\n",
      "Epoch 20: val_loss did not improve from 0.03707\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
      "Epoch 21/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0154\n",
      "Epoch 21: val_loss did not improve from 0.03707\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0394 - val_mean_squared_error: 0.0394\n",
      "Epoch 22/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
      "Epoch 22: val_loss did not improve from 0.03707\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n",
      "Epoch 23/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 23: val_loss improved from 0.03707 to 0.03707, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
      "Epoch 24/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 24: val_loss improved from 0.03707 to 0.03165, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0317 - val_mean_squared_error: 0.0317\n",
      "Epoch 25/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
      "Epoch 25: val_loss did not improve from 0.03165\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0332 - val_mean_squared_error: 0.0332\n",
      "Epoch 26/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0117\n",
      "Epoch 26: val_loss did not improve from 0.03165\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "Epoch 27/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 27: val_loss improved from 0.03165 to 0.03153, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0315 - val_mean_squared_error: 0.0315\n",
      "Epoch 28/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0105\n",
      "Epoch 28: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0539 - val_mean_squared_error: 0.0539\n",
      "Epoch 29/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0340 - mean_squared_error: 0.0340\n",
      "Epoch 29: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0368 - val_mean_squared_error: 0.0368\n",
      "Epoch 30/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0241 - mean_squared_error: 0.0241\n",
      "Epoch 30: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0396 - val_mean_squared_error: 0.0396\n",
      "Epoch 31/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0185\n",
      "Epoch 31: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0418 - val_mean_squared_error: 0.0418\n",
      "Epoch 32/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0150 - mean_squared_error: 0.0150\n",
      "Epoch 32: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0325 - val_mean_squared_error: 0.0325\n",
      "Epoch 33/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0193 - mean_squared_error: 0.0193\n",
      "Epoch 33: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0635 - val_mean_squared_error: 0.0635\n",
      "Epoch 34/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0285 - mean_squared_error: 0.0285\n",
      "Epoch 34: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0272 - mean_squared_error: 0.0272 - val_loss: 0.0331 - val_mean_squared_error: 0.0331\n",
      "Epoch 35/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0123\n",
      "Epoch 35: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0469 - val_mean_squared_error: 0.0469\n",
      "Epoch 36/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
      "Epoch 36: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
      "Epoch 37/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138\n",
      "Epoch 37: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
      "Epoch 38/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0124\n",
      "Epoch 38: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
      "Epoch 39/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0147 - mean_squared_error: 0.0147\n",
      "Epoch 39: val_loss did not improve from 0.03153\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0322 - val_mean_squared_error: 0.0322\n",
      "Epoch 40/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0102 - mean_squared_error: 0.0102\n",
      "Epoch 40: val_loss improved from 0.03153 to 0.03055, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
      "Epoch 41/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0135 - mean_squared_error: 0.0135\n",
      "Epoch 41: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0404 - val_mean_squared_error: 0.0404\n",
      "Epoch 42/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0214 - mean_squared_error: 0.0214\n",
      "Epoch 42: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0387 - val_mean_squared_error: 0.0387\n",
      "Epoch 43/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 43: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0566 - val_mean_squared_error: 0.0566\n",
      "Epoch 44/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0171\n",
      "Epoch 44: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0364 - val_mean_squared_error: 0.0364\n",
      "Epoch 45/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0218 - mean_squared_error: 0.0218\n",
      "Epoch 45: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
      "Epoch 46/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0117 - mean_squared_error: 0.0117\n",
      "Epoch 46: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0359 - val_mean_squared_error: 0.0359\n",
      "Epoch 47/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 47: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0567 - val_mean_squared_error: 0.0567\n",
      "Epoch 48/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0280 - mean_squared_error: 0.0280\n",
      "Epoch 48: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.1104 - val_mean_squared_error: 0.1104\n",
      "Epoch 49/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0767 - mean_squared_error: 0.0767\n",
      "Epoch 49: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0708 - mean_squared_error: 0.0708 - val_loss: 0.0395 - val_mean_squared_error: 0.0395\n",
      "Epoch 50/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0161\n",
      "Epoch 50: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
      "Epoch 51/500\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 51: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
      "Epoch 52/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0176 - mean_squared_error: 0.0176\n",
      "Epoch 52: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0538 - val_mean_squared_error: 0.0538\n",
      "Epoch 53/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0174\n",
      "Epoch 53: val_loss did not improve from 0.03055\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0391 - val_mean_squared_error: 0.0391\n",
      "Epoch 54/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0159 - mean_squared_error: 0.0159\n",
      "Epoch 54: val_loss improved from 0.03055 to 0.03045, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0305 - val_mean_squared_error: 0.0305\n",
      "Epoch 55/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0224\n",
      "Epoch 55: val_loss did not improve from 0.03045\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0359 - val_mean_squared_error: 0.0359\n",
      "Epoch 56/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 56: val_loss did not improve from 0.03045\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
      "Epoch 57/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0398 - mean_squared_error: 0.0398\n",
      "Epoch 57: val_loss did not improve from 0.03045\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.1136 - val_mean_squared_error: 0.1136\n",
      "Epoch 58/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0678 - mean_squared_error: 0.0678\n",
      "Epoch 58: val_loss did not improve from 0.03045\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0678 - mean_squared_error: 0.0678 - val_loss: 0.1131 - val_mean_squared_error: 0.1131\n",
      "Epoch 59/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0573 - mean_squared_error: 0.0573\n",
      "Epoch 59: val_loss did not improve from 0.03045\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0618 - mean_squared_error: 0.0618 - val_loss: 0.0904 - val_mean_squared_error: 0.0904\n",
      "Epoch 60/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0517 - mean_squared_error: 0.0517\n",
      "Epoch 60: val_loss did not improve from 0.03045\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0517 - mean_squared_error: 0.0517 - val_loss: 0.0325 - val_mean_squared_error: 0.0325\n",
      "Epoch 61/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0171\n",
      "Epoch 61: val_loss improved from 0.03045 to 0.02452, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0245 - val_mean_squared_error: 0.0245\n",
      "Epoch 62/500\n",
      "21/30 [====================>.........] - ETA: 0s - loss: 0.0148 - mean_squared_error: 0.0148\n",
      "Epoch 62: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0249 - val_mean_squared_error: 0.0249\n",
      "Epoch 63/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0146\n",
      "Epoch 63: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0258 - val_mean_squared_error: 0.0258\n",
      "Epoch 64/500\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 0.0218 - mean_squared_error: 0.0218\n",
      "Epoch 64: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0619 - val_mean_squared_error: 0.0619\n",
      "Epoch 65/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0146 - mean_squared_error: 0.0146\n",
      "Epoch 65: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0746 - val_mean_squared_error: 0.0746\n",
      "Epoch 66/500\n",
      "21/30 [====================>.........] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0181\n",
      "Epoch 66: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0261 - val_mean_squared_error: 0.0261\n",
      "Epoch 67/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 67: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0246 - val_mean_squared_error: 0.0246\n",
      "Epoch 68/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0094 - mean_squared_error: 0.0094\n",
      "Epoch 68: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "Epoch 69/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0244 - mean_squared_error: 0.0244\n",
      "Epoch 69: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
      "Epoch 70/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0330 - mean_squared_error: 0.0330\n",
      "Epoch 70: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
      "Epoch 71/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0274 - mean_squared_error: 0.0274\n",
      "Epoch 71: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.0401 - val_mean_squared_error: 0.0401\n",
      "Epoch 72/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0202 - mean_squared_error: 0.0202\n",
      "Epoch 72: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
      "Epoch 73/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 73: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0265 - mean_squared_error: 0.0265 - val_loss: 0.0949 - val_mean_squared_error: 0.0949\n",
      "Epoch 74/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0764 - mean_squared_error: 0.0764\n",
      "Epoch 74: val_loss did not improve from 0.02452\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0406 - mean_squared_error: 0.0406 - val_loss: 0.0340 - val_mean_squared_error: 0.0340\n",
      "Epoch 75/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118\n",
      "Epoch 75: val_loss improved from 0.02452 to 0.02335, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0234 - val_mean_squared_error: 0.0234\n",
      "Epoch 76/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 76: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
      "Epoch 77/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0278 - mean_squared_error: 0.0278\n",
      "Epoch 77: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0278 - val_mean_squared_error: 0.0278\n",
      "Epoch 78/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 78: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
      "Epoch 79/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 79: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0517 - mean_squared_error: 0.0517 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
      "Epoch 80/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0261 - mean_squared_error: 0.0261\n",
      "Epoch 80: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0521 - mean_squared_error: 0.0521 - val_loss: 0.0552 - val_mean_squared_error: 0.0552\n",
      "Epoch 81/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0191 - mean_squared_error: 0.0191\n",
      "Epoch 81: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
      "Epoch 82/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0294 - mean_squared_error: 0.0294\n",
      "Epoch 82: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
      "Epoch 83/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0257 - mean_squared_error: 0.0257\n",
      "Epoch 83: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0235 - val_mean_squared_error: 0.0235\n",
      "Epoch 84/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 84: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0677 - val_mean_squared_error: 0.0677\n",
      "Epoch 85/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0181 - mean_squared_error: 0.0181\n",
      "Epoch 85: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
      "Epoch 86/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 86: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0591 - val_mean_squared_error: 0.0591\n",
      "Epoch 87/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0366 - mean_squared_error: 0.0366\n",
      "Epoch 87: val_loss did not improve from 0.02335\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0702 - val_mean_squared_error: 0.0702\n",
      "Epoch 88/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0736 - mean_squared_error: 0.0736\n",
      "Epoch 88: val_loss improved from 0.02335 to 0.01969, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "Epoch 89/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 89: val_loss improved from 0.01969 to 0.01931, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0193 - val_mean_squared_error: 0.0193\n",
      "Epoch 90/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0244 - mean_squared_error: 0.0244\n",
      "Epoch 90: val_loss did not improve from 0.01931\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0825 - val_mean_squared_error: 0.0825\n",
      "Epoch 91/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0241 - mean_squared_error: 0.0241\n",
      "Epoch 91: val_loss did not improve from 0.01931\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0467 - val_mean_squared_error: 0.0467\n",
      "Epoch 92/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0327 - mean_squared_error: 0.0327\n",
      "Epoch 92: val_loss did not improve from 0.01931\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0269 - val_mean_squared_error: 0.0269\n",
      "Epoch 93/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 93: val_loss did not improve from 0.01931\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0596 - val_mean_squared_error: 0.0596\n",
      "Epoch 94/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0442 - mean_squared_error: 0.0442\n",
      "Epoch 94: val_loss did not improve from 0.01931\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0318 - val_mean_squared_error: 0.0318\n",
      "Epoch 95/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0139 - mean_squared_error: 0.0139\n",
      "Epoch 95: val_loss did not improve from 0.01931\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0278 - val_mean_squared_error: 0.0278\n",
      "Epoch 96/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111\n",
      "Epoch 96: val_loss did not improve from 0.01931\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0414 - val_mean_squared_error: 0.0414\n",
      "Epoch 97/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 97: val_loss improved from 0.01931 to 0.01786, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 98/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0165\n",
      "Epoch 98: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
      "Epoch 99/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0123\n",
      "Epoch 99: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0224 - val_mean_squared_error: 0.0224\n",
      "Epoch 100/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0377 - mean_squared_error: 0.0377\n",
      "Epoch 100: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
      "Epoch 101/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0438 - mean_squared_error: 0.0438\n",
      "Epoch 101: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0436 - mean_squared_error: 0.0436 - val_loss: 0.0273 - val_mean_squared_error: 0.0273\n",
      "Epoch 102/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0119\n",
      "Epoch 102: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0427 - val_mean_squared_error: 0.0427\n",
      "Epoch 103/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0171\n",
      "Epoch 103: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
      "Epoch 104/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 104: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.1098 - val_mean_squared_error: 0.1098\n",
      "Epoch 105/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.1028 - mean_squared_error: 0.1028\n",
      "Epoch 105: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0861 - val_mean_squared_error: 0.0861\n",
      "Epoch 106/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0248 - mean_squared_error: 0.0248\n",
      "Epoch 106: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0548 - val_mean_squared_error: 0.0548\n",
      "Epoch 107/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 107: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0301 - val_mean_squared_error: 0.0301\n",
      "Epoch 108/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0149 - mean_squared_error: 0.0149\n",
      "Epoch 108: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0270 - val_mean_squared_error: 0.0270\n",
      "Epoch 109/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0132 - mean_squared_error: 0.0132\n",
      "Epoch 109: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "Epoch 110/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 110: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
      "Epoch 111/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0133 - mean_squared_error: 0.0133\n",
      "Epoch 111: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
      "Epoch 112/500\n",
      "21/30 [====================>.........] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.0186\n",
      "Epoch 112: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0414 - val_mean_squared_error: 0.0414\n",
      "Epoch 113/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0262 - mean_squared_error: 0.0262\n",
      "Epoch 113: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 114/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0160\n",
      "Epoch 114: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0253 - val_mean_squared_error: 0.0253\n",
      "Epoch 115/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0172\n",
      "Epoch 115: val_loss did not improve from 0.01786\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
      "Epoch 116/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 116: val_loss improved from 0.01786 to 0.01763, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 117/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 117: val_loss improved from 0.01763 to 0.01739, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "Epoch 118/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 118: val_loss improved from 0.01739 to 0.01683, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 119/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 119: val_loss did not improve from 0.01683\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0259 - val_mean_squared_error: 0.0259\n",
      "Epoch 120/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 120: val_loss did not improve from 0.01683\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
      "Epoch 121/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 121: val_loss did not improve from 0.01683\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0256 - val_mean_squared_error: 0.0256\n",
      "Epoch 122/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0112\n",
      "Epoch 122: val_loss did not improve from 0.01683\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 123/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 123: val_loss did not improve from 0.01683\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "Epoch 124/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 124: val_loss did not improve from 0.01683\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 125/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0065 - mean_squared_error: 0.0065\n",
      "Epoch 125: val_loss did not improve from 0.01683\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0296 - val_mean_squared_error: 0.0296\n",
      "Epoch 126/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0186 - mean_squared_error: 0.0186\n",
      "Epoch 126: val_loss did not improve from 0.01683\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
      "Epoch 127/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0342 - mean_squared_error: 0.0342\n",
      "Epoch 127: val_loss did not improve from 0.01683\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
      "Epoch 128/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 128: val_loss improved from 0.01683 to 0.01575, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 129/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 129: val_loss did not improve from 0.01575\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 130/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 130: val_loss did not improve from 0.01575\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "Epoch 131/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 131: val_loss did not improve from 0.01575\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "Epoch 132/500\n",
      "21/30 [====================>.........] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 132: val_loss did not improve from 0.01575\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 133/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 133: val_loss did not improve from 0.01575\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "Epoch 134/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 134: val_loss did not improve from 0.01575\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 135/500\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 135: val_loss did not improve from 0.01575\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0690 - val_mean_squared_error: 0.0690\n",
      "Epoch 136/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0177 - mean_squared_error: 0.0177\n",
      "Epoch 136: val_loss improved from 0.01575 to 0.01555, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 137/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 137: val_loss did not improve from 0.01555\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "Epoch 138/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 138: val_loss did not improve from 0.01555\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 139/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126\n",
      "Epoch 139: val_loss did not improve from 0.01555\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0383 - val_mean_squared_error: 0.0383\n",
      "Epoch 140/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138\n",
      "Epoch 140: val_loss did not improve from 0.01555\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.1024 - val_mean_squared_error: 0.1024\n",
      "Epoch 141/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0292\n",
      "Epoch 141: val_loss did not improve from 0.01555\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0383 - val_mean_squared_error: 0.0383\n",
      "Epoch 142/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0167\n",
      "Epoch 142: val_loss did not improve from 0.01555\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 143/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 143: val_loss improved from 0.01555 to 0.01505, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 144/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 144: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 145/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 145: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 146/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 146: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
      "Epoch 147/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 147: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 148/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 148: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 149/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 149: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 150/500\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 150: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 151/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 151: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 152/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 152: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 153/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 153: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "Epoch 154/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 154: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 155/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 155: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0271 - val_mean_squared_error: 0.0271\n",
      "Epoch 156/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 156: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 157/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 157: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0322 - val_mean_squared_error: 0.0322\n",
      "Epoch 158/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 158: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 159/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 159: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 160/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 160: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 161/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 161: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0667 - val_mean_squared_error: 0.0667\n",
      "Epoch 162/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0199 - mean_squared_error: 0.0199\n",
      "Epoch 162: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0285 - val_mean_squared_error: 0.0285\n",
      "Epoch 163/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0137 - mean_squared_error: 0.0137\n",
      "Epoch 163: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0264 - val_mean_squared_error: 0.0264\n",
      "Epoch 164/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 164: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0333 - val_mean_squared_error: 0.0333\n",
      "Epoch 165/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0267 - mean_squared_error: 0.0267\n",
      "Epoch 165: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0343 - val_mean_squared_error: 0.0343\n",
      "Epoch 166/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0171\n",
      "Epoch 166: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0322 - val_mean_squared_error: 0.0322\n",
      "Epoch 167/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 167: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "Epoch 168/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 168: val_loss did not improve from 0.01505\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0227 - val_mean_squared_error: 0.0227\n",
      "Epoch 169/500\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 169: val_loss improved from 0.01505 to 0.01308, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
      "Epoch 170/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 170: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 171/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 171: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
      "Epoch 172/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 172: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 173/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 173: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 174/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 174: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "Epoch 175/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 175: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 176/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 176: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 177/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 177: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 178/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 178: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 179/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 179: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 180/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 180: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 181/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0015 - mean_squared_error: 0.0015\n",
      "Epoch 181: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 182/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041        \n",
      "Epoch 182: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0183 - val_mean_squared_error: 0.0183\n",
      "Epoch 183/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 183: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 184/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 184: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
      "Epoch 185/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0080 - mean_squared_error: 0.0080\n",
      "Epoch 185: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 186/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 186: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 187/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 187: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 188/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 188: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 189/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 189: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 190/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 190: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
      "Epoch 191/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 191: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 192/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 192: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 193/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 193: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 194/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 194: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 195/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 195: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0607 - val_mean_squared_error: 0.0607\n",
      "Epoch 196/500\n",
      "18/30 [=================>............] - ETA: 0s - loss: 0.0156 - mean_squared_error: 0.0156\n",
      "Epoch 196: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0273 - val_mean_squared_error: 0.0273\n",
      "Epoch 197/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141\n",
      "Epoch 197: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 198/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 198: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Epoch 199/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 199: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 200/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 200: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0242 - val_mean_squared_error: 0.0242\n",
      "Epoch 201/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 201: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 202/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 202: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 203/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 203: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "Epoch 204/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 204: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 205/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 205: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 206/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 206: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 207/500\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 207: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0193 - val_mean_squared_error: 0.0193\n",
      "Epoch 208/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 208: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 209/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 209: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 210/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 210: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 211/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 211: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 212/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 212: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "Epoch 213/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 213: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "Epoch 214/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 214: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 215/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 215: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 216/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 216: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0267 - val_mean_squared_error: 0.0267\n",
      "Epoch 217/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 217: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0578 - val_mean_squared_error: 0.0578\n",
      "Epoch 218/500\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0163\n",
      "Epoch 218: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 219/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128\n",
      "Epoch 219: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0264 - val_mean_squared_error: 0.0264\n",
      "Epoch 220/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 220: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 221/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 221: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 222/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 222: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0227 - val_mean_squared_error: 0.0227\n",
      "Epoch 223/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 223: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
      "Epoch 224/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 8.8427e-04 - mean_squared_error: 8.8427e-04\n",
      "Epoch 224: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 225/500\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 225: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
      "Epoch 226/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 226: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0229 - val_mean_squared_error: 0.0229\n",
      "Epoch 227/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 227: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 228/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 228: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 229/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 229: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 230/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 230: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
      "Epoch 231/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 231: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
      "Epoch 232/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 232: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0351 - val_mean_squared_error: 0.0351\n",
      "Epoch 233/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 233: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 234/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 234: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0193 - val_mean_squared_error: 0.0193\n",
      "Epoch 235/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 235: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 236/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 236: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 237/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 237: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0248 - val_mean_squared_error: 0.0248\n",
      "Epoch 238/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 238: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 239/500\n",
      "17/30 [================>.............] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 239: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 240/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047        \n",
      "Epoch 240: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
      "Epoch 241/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 241: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "Epoch 242/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 242: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
      "Epoch 243/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 243: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 244/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 244: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 245/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 245: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 246/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 246: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0284 - val_mean_squared_error: 0.0284\n",
      "Epoch 247/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0160 - mean_squared_error: 0.0160\n",
      "Epoch 247: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
      "Epoch 248/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 248: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
      "Epoch 249/500\n",
      "21/30 [====================>.........] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 249: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 250/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 250: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 251/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 251: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0808 - val_mean_squared_error: 0.0808\n",
      "Epoch 252/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0729 - mean_squared_error: 0.0729\n",
      "Epoch 252: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0270 - val_mean_squared_error: 0.0270\n",
      "Epoch 253/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0120 - mean_squared_error: 0.0120\n",
      "Epoch 253: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0299 - val_mean_squared_error: 0.0299\n",
      "Epoch 254/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0079 - mean_squared_error: 0.0079\n",
      "Epoch 254: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
      "Epoch 255/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0130 - mean_squared_error: 0.0130\n",
      "Epoch 255: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0260 - val_mean_squared_error: 0.0260\n",
      "Epoch 256/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0143 - mean_squared_error: 0.0143\n",
      "Epoch 256: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 257/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0142 - mean_squared_error: 0.0142\n",
      "Epoch 257: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 258/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "Epoch 258: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0237 - val_mean_squared_error: 0.0237\n",
      "Epoch 259/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 259: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0253 - val_mean_squared_error: 0.0253\n",
      "Epoch 260/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 260: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 261/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 261: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
      "Epoch 262/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 262: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Epoch 263/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 263: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 264/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 264: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "Epoch 265/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 265: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "Epoch 266/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 266: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 267/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 267: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 268/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 268: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0311 - val_mean_squared_error: 0.0311\n",
      "Epoch 269/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 269: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0191 - val_mean_squared_error: 0.0191\n",
      "Epoch 270/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 270: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
      "Epoch 271/500\n",
      "18/30 [=================>............] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 271: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 272/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 272: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 273/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0078 - mean_squared_error: 0.0078\n",
      "Epoch 273: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
      "Epoch 274/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 274: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0247 - val_mean_squared_error: 0.0247\n",
      "Epoch 275/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 275: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 276/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 276: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
      "Epoch 277/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 277: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 278/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 278: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 279/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 279: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 280/500\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 280: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 281/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 281: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 282/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 282: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "Epoch 283/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027        \n",
      "Epoch 283: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 284/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 284: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
      "Epoch 285/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 285: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
      "Epoch 286/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0109 - mean_squared_error: 0.0109\n",
      "Epoch 286: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 287/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 287: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0281 - val_mean_squared_error: 0.0281\n",
      "Epoch 288/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 288: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "Epoch 289/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 289: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "Epoch 290/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 290: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0384 - val_mean_squared_error: 0.0384\n",
      "Epoch 291/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 291: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 292/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0097 - mean_squared_error: 0.0097\n",
      "Epoch 292: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 293/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 293: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 294/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 294: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0237 - val_mean_squared_error: 0.0237\n",
      "Epoch 295/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 295: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "Epoch 296/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 296: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "Epoch 297/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 297: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "Epoch 298/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 298: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 299/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 299: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 300/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 300: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 301/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 301: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 302/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034        \n",
      "Epoch 302: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0289 - val_mean_squared_error: 0.0289\n",
      "Epoch 303/500\n",
      "19/30 [==================>...........] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 303: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0242 - val_mean_squared_error: 0.0242\n",
      "Epoch 304/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 304: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0298 - val_mean_squared_error: 0.0298\n",
      "Epoch 305/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 305: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Epoch 306/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 306: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0302 - val_mean_squared_error: 0.0302\n",
      "Epoch 307/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 307: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "Epoch 308/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 308: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
      "Epoch 309/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0092 - mean_squared_error: 0.0092\n",
      "Epoch 309: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 310/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 310: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0278 - val_mean_squared_error: 0.0278\n",
      "Epoch 311/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 311: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
      "Epoch 312/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 312: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "Epoch 313/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 313: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "Epoch 314/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0081 - mean_squared_error: 0.0081\n",
      "Epoch 314: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0238 - val_mean_squared_error: 0.0238\n",
      "Epoch 315/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 315: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0562 - val_mean_squared_error: 0.0562\n",
      "Epoch 316/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0141 - mean_squared_error: 0.0141\n",
      "Epoch 316: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "Epoch 317/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0083 - mean_squared_error: 0.0083\n",
      "Epoch 317: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 318/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0114 - mean_squared_error: 0.0114\n",
      "Epoch 318: val_loss did not improve from 0.01308\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 319/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 319: val_loss improved from 0.01308 to 0.01284, saving model to model.weights.best.hdf5\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
      "Epoch 320/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 320: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 321/500\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 321: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 322/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 322: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
      "Epoch 323/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 323: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 324/500\n",
      "19/30 [==================>...........] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 324: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0318 - val_mean_squared_error: 0.0318\n",
      "Epoch 325/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 325: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 326/500\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 326: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Epoch 327/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 327: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 328/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 328: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
      "Epoch 329/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 329: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 330/500\n",
      "21/30 [====================>.........] - ETA: 0s - loss: 0.0050 - mean_squared_error: 0.0050\n",
      "Epoch 330: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 331/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 331: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 332/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 332: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "Epoch 333/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 333: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 334/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021        \n",
      "Epoch 334: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0244 - val_mean_squared_error: 0.0244\n",
      "Epoch 335/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 335: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
      "Epoch 336/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 336: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 337/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 337: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 338/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0165\n",
      "Epoch 338: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "Epoch 339/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0237\n",
      "Epoch 339: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
      "Epoch 340/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0233 - mean_squared_error: 0.0233\n",
      "Epoch 340: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
      "Epoch 341/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0107 - mean_squared_error: 0.0107\n",
      "Epoch 341: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
      "Epoch 342/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 342: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "Epoch 343/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 343: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 344/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 344: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 345/500\n",
      "18/30 [=================>............] - ETA: 0s - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 345: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 346/500\n",
      "22/30 [=====================>........] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 346: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n",
      "Epoch 347/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "Epoch 347: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
      "Epoch 348/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0166\n",
      "Epoch 348: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0279 - val_mean_squared_error: 0.0279\n",
      "Epoch 349/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0209 - mean_squared_error: 0.0209\n",
      "Epoch 349: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
      "Epoch 350/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0084 - mean_squared_error: 0.0084\n",
      "Epoch 350: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
      "Epoch 351/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 351: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
      "Epoch 352/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 352: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "Epoch 353/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0131 - mean_squared_error: 0.0131\n",
      "Epoch 353: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 354/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 354: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0326 - val_mean_squared_error: 0.0326\n",
      "Epoch 355/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0077 - mean_squared_error: 0.0077\n",
      "Epoch 355: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
      "Epoch 356/500\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 356: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 357/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 357: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "Epoch 358/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 358: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
      "Epoch 359/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 359: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0307 - val_mean_squared_error: 0.0307\n",
      "Epoch 360/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0144 - mean_squared_error: 0.0144\n",
      "Epoch 360: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 361/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 361: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 362/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0185 - mean_squared_error: 0.0185\n",
      "Epoch 362: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0267 - val_mean_squared_error: 0.0267\n",
      "Epoch 363/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0070 - mean_squared_error: 0.0070\n",
      "Epoch 363: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 364/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 364: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Epoch 365/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 365: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Epoch 366/500\n",
      "18/30 [=================>............] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 366: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0244 - val_mean_squared_error: 0.0244\n",
      "Epoch 367/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 367: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
      "Epoch 368/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0054 - mean_squared_error: 0.0054        \n",
      "Epoch 368: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0249 - val_mean_squared_error: 0.0249\n",
      "Epoch 369/500\n",
      "18/30 [=================>............] - ETA: 0s - loss: 0.0075 - mean_squared_error: 0.0075\n",
      "Epoch 369: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 370/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 370: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0288 - val_mean_squared_error: 0.0288\n",
      "Epoch 371/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0178 - mean_squared_error: 0.0178\n",
      "Epoch 371: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0318 - val_mean_squared_error: 0.0318\n",
      "Epoch 372/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 372: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 373/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 373: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "Epoch 374/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 374: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 375/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 375: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0323 - val_mean_squared_error: 0.0323\n",
      "Epoch 376/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0170\n",
      "Epoch 376: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 377/500\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 377: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "Epoch 378/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 378: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 379/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 379: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 380/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 380: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 381/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 381: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 382/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 382: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0276 - val_mean_squared_error: 0.0276\n",
      "Epoch 383/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0046 - mean_squared_error: 0.0046\n",
      "Epoch 383: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 384/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 384: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "Epoch 385/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 385: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 386/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 386: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0228 - val_mean_squared_error: 0.0228\n",
      "Epoch 387/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 387: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0254 - val_mean_squared_error: 0.0254\n",
      "Epoch 388/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 388: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 389/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 389: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 390/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 390: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 391/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0025 - mean_squared_error: 0.0025        \n",
      "Epoch 391: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 392/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 392: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 393/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0016 - mean_squared_error: 0.0016        \n",
      "Epoch 393: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 394/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 394: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 395/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 395: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 396/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0013 - mean_squared_error: 0.0013        \n",
      "Epoch 396: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0267 - val_mean_squared_error: 0.0267\n",
      "Epoch 397/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0119 - mean_squared_error: 0.0119\n",
      "Epoch 397: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "Epoch 398/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 398: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0395 - val_mean_squared_error: 0.0395\n",
      "Epoch 399/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0128 - mean_squared_error: 0.0128\n",
      "Epoch 399: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 400/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 400: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 401/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 401: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 402/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 402: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0224 - val_mean_squared_error: 0.0224\n",
      "Epoch 403/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 403: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
      "Epoch 404/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 404: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 405/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 405: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 406/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 406: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 407/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 407: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0245 - val_mean_squared_error: 0.0245\n",
      "Epoch 408/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 408: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 409/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 409: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "Epoch 410/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 410: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "Epoch 411/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0072 - mean_squared_error: 0.0072\n",
      "Epoch 411: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 412/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 412: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 413/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 413: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 414/500\n",
      "23/30 [======================>.......] - ETA: 0s - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 414: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "Epoch 415/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 415: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0325 - val_mean_squared_error: 0.0325\n",
      "Epoch 416/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0112 - mean_squared_error: 0.0112\n",
      "Epoch 416: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0482 - val_mean_squared_error: 0.0482\n",
      "Epoch 417/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0192\n",
      "Epoch 417: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0263 - val_mean_squared_error: 0.0263\n",
      "Epoch 418/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103\n",
      "Epoch 418: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "Epoch 419/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0163\n",
      "Epoch 419: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "Epoch 420/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0220 - mean_squared_error: 0.0220\n",
      "Epoch 420: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0248 - val_mean_squared_error: 0.0248\n",
      "Epoch 421/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0371 - mean_squared_error: 0.0371\n",
      "Epoch 421: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 422/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0123 - mean_squared_error: 0.0123\n",
      "Epoch 422: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 423/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087\n",
      "Epoch 423: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 424/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0145 - mean_squared_error: 0.0145\n",
      "Epoch 424: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0298 - val_mean_squared_error: 0.0298\n",
      "Epoch 425/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100\n",
      "Epoch 425: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0535 - val_mean_squared_error: 0.0535\n",
      "Epoch 426/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0251 - mean_squared_error: 0.0251\n",
      "Epoch 426: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0398 - val_mean_squared_error: 0.0398\n",
      "Epoch 427/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0211\n",
      "Epoch 427: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
      "Epoch 428/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 428: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0332 - val_mean_squared_error: 0.0332\n",
      "Epoch 429/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "Epoch 429: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 430/500\n",
      "20/30 [===================>..........] - ETA: 0s - loss: 0.0086 - mean_squared_error: 0.0086\n",
      "Epoch 430: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "Epoch 431/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 431: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 432/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 432: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
      "Epoch 433/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 433: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0235 - val_mean_squared_error: 0.0235\n",
      "Epoch 434/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 434: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
      "Epoch 435/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0124\n",
      "Epoch 435: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n",
      "Epoch 436/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0095 - mean_squared_error: 0.0095\n",
      "Epoch 436: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "Epoch 437/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0055 - mean_squared_error: 0.0055\n",
      "Epoch 437: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "Epoch 438/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 438: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "Epoch 439/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 439: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0258 - val_mean_squared_error: 0.0258\n",
      "Epoch 440/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0154 - mean_squared_error: 0.0154\n",
      "Epoch 440: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0375 - val_mean_squared_error: 0.0375\n",
      "Epoch 441/500\n",
      "21/30 [====================>.........] - ETA: 0s - loss: 0.0122 - mean_squared_error: 0.0122\n",
      "Epoch 441: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 442/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0085 - mean_squared_error: 0.0085\n",
      "Epoch 442: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 443/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 443: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
      "Epoch 444/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0048 - mean_squared_error: 0.0048\n",
      "Epoch 444: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "Epoch 445/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 445: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0202 - val_mean_squared_error: 0.0202\n",
      "Epoch 446/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056\n",
      "Epoch 446: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 447/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 447: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "Epoch 448/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 448: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
      "Epoch 449/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 449: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "Epoch 450/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 450: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
      "Epoch 451/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 451: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "Epoch 452/500\n",
      "18/30 [=================>............] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 452: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0259 - val_mean_squared_error: 0.0259\n",
      "Epoch 453/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0054 - mean_squared_error: 0.0054\n",
      "Epoch 453: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 454/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 454: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "Epoch 455/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 455: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "Epoch 456/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 456: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
      "Epoch 457/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 457: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "Epoch 458/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 458: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "Epoch 459/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 459: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
      "Epoch 460/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 460: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
      "Epoch 461/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029        \n",
      "Epoch 461: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n",
      "Epoch 462/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0049 - mean_squared_error: 0.0049\n",
      "Epoch 462: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "Epoch 463/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 463: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "Epoch 464/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 464: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0205 - val_mean_squared_error: 0.0205\n",
      "Epoch 465/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 465: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
      "Epoch 466/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066\n",
      "Epoch 466: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
      "Epoch 467/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0047 - mean_squared_error: 0.0047\n",
      "Epoch 467: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0244 - val_mean_squared_error: 0.0244\n",
      "Epoch 468/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 468: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n",
      "Epoch 469/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 469: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0286 - val_mean_squared_error: 0.0286\n",
      "Epoch 470/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 470: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0299 - val_mean_squared_error: 0.0299\n",
      "Epoch 471/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0074 - mean_squared_error: 0.0074\n",
      "Epoch 471: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
      "Epoch 472/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0058 - mean_squared_error: 0.0058\n",
      "Epoch 472: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "Epoch 473/500\n",
      "17/30 [================>.............] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 473: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
      "Epoch 474/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0093 - mean_squared_error: 0.0093\n",
      "Epoch 474: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 475/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 475: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 476/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_squared_error: 0.0039\n",
      "Epoch 476: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
      "Epoch 477/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0125 - mean_squared_error: 0.0125\n",
      "Epoch 477: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0212 - val_mean_squared_error: 0.0212\n",
      "Epoch 478/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0091\n",
      "Epoch 478: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 479/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071\n",
      "Epoch 479: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 480/500\n",
      "21/30 [====================>.........] - ETA: 0s - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 480: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
      "Epoch 481/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 481: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0275 - val_mean_squared_error: 0.0275\n",
      "Epoch 482/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 482: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
      "Epoch 483/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059\n",
      "Epoch 483: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
      "Epoch 484/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0068 - mean_squared_error: 0.0068\n",
      "Epoch 484: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0183 - val_mean_squared_error: 0.0183\n",
      "Epoch 485/500\n",
      "29/30 [============================>.] - ETA: 0s - loss: 0.0060 - mean_squared_error: 0.0060\n",
      "Epoch 485: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 486/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 486: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0208 - val_mean_squared_error: 0.0208\n",
      "Epoch 487/500\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 487: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "Epoch 488/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 488: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 489/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018        \n",
      "Epoch 489: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 490/500\n",
      " 1/30 [>.............................] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029\n",
      "Epoch 490: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0268 - val_mean_squared_error: 0.0268\n",
      "Epoch 491/500\n",
      "26/30 [=========================>....] - ETA: 0s - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 491: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0280 - val_mean_squared_error: 0.0280\n",
      "Epoch 492/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0061 - mean_squared_error: 0.0061\n",
      "Epoch 492: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
      "Epoch 493/500\n",
      "24/30 [=======================>......] - ETA: 0s - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 493: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 494/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 494: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "Epoch 495/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 495: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 496/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 496: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0183 - val_mean_squared_error: 0.0183\n",
      "Epoch 497/500\n",
      "27/30 [==========================>...] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 497: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 498/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024        \n",
      "Epoch 498: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0348 - val_mean_squared_error: 0.0348\n",
      "Epoch 499/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062\n",
      "Epoch 499: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "Epoch 500/500\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.0067 - mean_squared_error: 0.0067\n",
      "Epoch 500: val_loss did not improve from 0.01284\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0254 - val_mean_squared_error: 0.0254\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e7894f-247a-4ef1-b112-49c6f98622a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78.15619659423828,\n",
       " 2.6343064308166504,\n",
       " 0.26712489128112793,\n",
       " 0.10397613793611526,\n",
       " 0.07540229707956314,\n",
       " 0.04236205294728279,\n",
       " 0.032412830740213394,\n",
       " 0.02555810660123825,\n",
       " 0.019352875649929047,\n",
       " 0.019053079187870026,\n",
       " 0.016671229153871536,\n",
       " 0.014829742722213268,\n",
       " 0.012550712563097477,\n",
       " 0.012423730455338955,\n",
       " 0.01271012518554926,\n",
       " 0.013344723731279373,\n",
       " 0.017609307542443275,\n",
       " 0.021802715957164764,\n",
       " 0.021096348762512207,\n",
       " 0.02547307312488556,\n",
       " 0.016233962029218674,\n",
       " 0.01463253516703844,\n",
       " 0.011849777773022652,\n",
       " 0.011085286736488342,\n",
       " 0.01075891125947237,\n",
       " 0.011706535704433918,\n",
       " 0.010310828685760498,\n",
       " 0.010717175900936127,\n",
       " 0.03327189013361931,\n",
       " 0.023676671087741852,\n",
       " 0.018837330862879753,\n",
       " 0.014881392940878868,\n",
       " 0.019029326736927032,\n",
       " 0.027234885841608047,\n",
       " 0.015545360743999481,\n",
       " 0.012743435800075531,\n",
       " 0.01393524743616581,\n",
       " 0.01227558869868517,\n",
       " 0.014056732878088951,\n",
       " 0.011289922520518303,\n",
       " 0.012516332790255547,\n",
       " 0.021282073110342026,\n",
       " 0.018362194299697876,\n",
       " 0.01735520176589489,\n",
       " 0.0184125117957592,\n",
       " 0.011022815480828285,\n",
       " 0.010718686506152153,\n",
       " 0.026413656771183014,\n",
       " 0.07084088772535324,\n",
       " 0.028780074790120125,\n",
       " 0.020580574870109558,\n",
       " 0.01748460717499256,\n",
       " 0.01695415936410427,\n",
       " 0.016364188864827156,\n",
       " 0.026331983506679535,\n",
       " 0.024388380348682404,\n",
       " 0.038730520755052567,\n",
       " 0.06780190020799637,\n",
       " 0.061759211122989655,\n",
       " 0.05172412097454071,\n",
       " 0.017185425385832787,\n",
       " 0.014961975626647472,\n",
       " 0.014626511372625828,\n",
       " 0.021755922585725784,\n",
       " 0.014570857398211956,\n",
       " 0.01614956744015217,\n",
       " 0.00884124357253313,\n",
       " 0.009432166814804077,\n",
       " 0.021742533892393112,\n",
       " 0.020637476816773415,\n",
       " 0.027399705722928047,\n",
       " 0.0197981558740139,\n",
       " 0.026488259434700012,\n",
       " 0.040569428354501724,\n",
       " 0.013100032694637775,\n",
       " 0.01956021413207054,\n",
       " 0.015754221007227898,\n",
       " 0.01599922589957714,\n",
       " 0.05172589048743248,\n",
       " 0.052069779485464096,\n",
       " 0.02051309309899807,\n",
       " 0.04008620232343674,\n",
       " 0.01734212040901184,\n",
       " 0.012073220685124397,\n",
       " 0.018052611500024796,\n",
       " 0.01180160790681839,\n",
       " 0.016120895743370056,\n",
       " 0.013182888738811016,\n",
       " 0.010320847854018211,\n",
       " 0.02439863421022892,\n",
       " 0.024071549996733665,\n",
       " 0.01895912177860737,\n",
       " 0.0220046266913414,\n",
       " 0.013182900846004486,\n",
       " 0.013638620264828205,\n",
       " 0.016087481752038002,\n",
       " 0.01093896571546793,\n",
       " 0.016454581171274185,\n",
       " 0.012242860160768032,\n",
       " 0.037848588079214096,\n",
       " 0.0436277836561203,\n",
       " 0.011860252358019352,\n",
       " 0.017132457345724106,\n",
       " 0.009680981747806072,\n",
       " 0.02354457974433899,\n",
       " 0.024819927290081978,\n",
       " 0.010556042194366455,\n",
       " 0.021446801722049713,\n",
       " 0.017438383772969246,\n",
       " 0.024817701429128647,\n",
       " 0.013161245733499527,\n",
       " 0.01855100318789482,\n",
       " 0.02568383328616619,\n",
       " 0.015797797590494156,\n",
       " 0.017018210142850876,\n",
       " 0.011453595012426376,\n",
       " 0.0070897918194532394,\n",
       " 0.007032776717096567,\n",
       " 0.007303871214389801,\n",
       " 0.007643633987754583,\n",
       " 0.01092572696506977,\n",
       " 0.013806493952870369,\n",
       " 0.00632445327937603,\n",
       " 0.004849989898502827,\n",
       " 0.006810457445681095,\n",
       " 0.018170561641454697,\n",
       " 0.03412150591611862,\n",
       " 0.010280434042215347,\n",
       " 0.007334493566304445,\n",
       " 0.0038624205626547337,\n",
       " 0.0046558803878724575,\n",
       " 0.004743050783872604,\n",
       " 0.005778218153864145,\n",
       " 0.008362636901438236,\n",
       " 0.0076318103820085526,\n",
       " 0.01808798313140869,\n",
       " 0.011315608397126198,\n",
       " 0.005495285615324974,\n",
       " 0.012809669598937035,\n",
       " 0.01329547818750143,\n",
       " 0.026314780116081238,\n",
       " 0.01626604236662388,\n",
       " 0.007931273430585861,\n",
       " 0.005808575544506311,\n",
       " 0.006976597476750612,\n",
       " 0.004662815015763044,\n",
       " 0.004105787258595228,\n",
       " 0.004496932495385408,\n",
       " 0.0033255331218242645,\n",
       " 0.0034687777515500784,\n",
       " 0.0037996817845851183,\n",
       " 0.0036209942772984505,\n",
       " 0.0030502858571708202,\n",
       " 0.004244365729391575,\n",
       " 0.0066993581131100655,\n",
       " 0.00526799913495779,\n",
       " 0.003955313470214605,\n",
       " 0.007417737971991301,\n",
       " 0.0036295324098318815,\n",
       " 0.004325786605477333,\n",
       " 0.003928228281438351,\n",
       " 0.019537370651960373,\n",
       " 0.013889934867620468,\n",
       " 0.008818190544843674,\n",
       " 0.027093829587101936,\n",
       " 0.016419576480984688,\n",
       " 0.008508854545652866,\n",
       " 0.00827060267329216,\n",
       " 0.004532726015895605,\n",
       " 0.004941239953041077,\n",
       " 0.0030249387491494417,\n",
       " 0.002530597848817706,\n",
       " 0.0038827117532491684,\n",
       " 0.005347722209990025,\n",
       " 0.005010799504816532,\n",
       " 0.007223312743008137,\n",
       " 0.0042356569319963455,\n",
       " 0.003068177495151758,\n",
       " 0.0025766112376004457,\n",
       " 0.0038793478161096573,\n",
       " 0.0031911192927509546,\n",
       " 0.0042355856858193874,\n",
       " 0.004720520693808794,\n",
       " 0.0032115138601511717,\n",
       " 0.0073539181612432,\n",
       " 0.004565615672618151,\n",
       " 0.004756859038025141,\n",
       " 0.004288577940315008,\n",
       " 0.004180543590337038,\n",
       " 0.0028057540766894817,\n",
       " 0.0023717498406767845,\n",
       " 0.0033100827131420374,\n",
       " 0.003518948797136545,\n",
       " 0.003151707584038377,\n",
       " 0.0022900481708347797,\n",
       " 0.011872048489749432,\n",
       " 0.012243208475410938,\n",
       " 0.005576267372816801,\n",
       " 0.005881310906261206,\n",
       " 0.005980645306408405,\n",
       " 0.004087826237082481,\n",
       " 0.003539252793416381,\n",
       " 0.0034823804162442684,\n",
       " 0.0025435348507016897,\n",
       " 0.005263432394713163,\n",
       " 0.003337420988827944,\n",
       " 0.0021864597219973803,\n",
       " 0.002976953284814954,\n",
       " 0.0025956735480576754,\n",
       " 0.0020315214060246944,\n",
       " 0.0029896055348217487,\n",
       " 0.0020827986299991608,\n",
       " 0.004398071672767401,\n",
       " 0.0017707385122776031,\n",
       " 0.005637780763208866,\n",
       " 0.007452217396348715,\n",
       " 0.009645594283938408,\n",
       " 0.016420302912592888,\n",
       " 0.012504271231591702,\n",
       " 0.0069478596560657024,\n",
       " 0.0037786795292049646,\n",
       " 0.0033837731461972,\n",
       " 0.004768661223351955,\n",
       " 0.0024473792873322964,\n",
       " 0.0057527003809809685,\n",
       " 0.0031982872169464827,\n",
       " 0.0043672118335962296,\n",
       " 0.0017632079543545842,\n",
       " 0.002349936868995428,\n",
       " 0.002825499512255192,\n",
       " 0.0035401463974267244,\n",
       " 0.002563866088166833,\n",
       " 0.006712588481605053,\n",
       " 0.003404294140636921,\n",
       " 0.006820098962634802,\n",
       " 0.003278830787166953,\n",
       " 0.003468588925898075,\n",
       " 0.005757980514317751,\n",
       " 0.0038409356493502855,\n",
       " 0.004169992171227932,\n",
       " 0.003580152988433838,\n",
       " 0.005234085954725742,\n",
       " 0.003304762067273259,\n",
       " 0.003150781150907278,\n",
       " 0.001975544961169362,\n",
       " 0.0066403839737176895,\n",
       " 0.014502529054880142,\n",
       " 0.004526912700384855,\n",
       " 0.003772409399971366,\n",
       " 0.0026600072160363197,\n",
       " 0.01068574097007513,\n",
       " 0.022503849118947983,\n",
       " 0.01206279918551445,\n",
       " 0.007759300991892815,\n",
       " 0.013583462685346603,\n",
       " 0.013836003839969635,\n",
       " 0.014352894388139248,\n",
       " 0.011921368539333344,\n",
       " 0.007879071868956089,\n",
       " 0.009667518548667431,\n",
       " 0.0038136679213494062,\n",
       " 0.004468176979571581,\n",
       " 0.0027685053646564484,\n",
       " 0.0045699672773480415,\n",
       " 0.003898724215105176,\n",
       " 0.004208593629300594,\n",
       " 0.002046427223831415,\n",
       " 0.003107344964519143,\n",
       " 0.004447979386895895,\n",
       " 0.002994864946231246,\n",
       " 0.005409923382103443,\n",
       " 0.0023159466218203306,\n",
       " 0.007785975467413664,\n",
       " 0.00490557262673974,\n",
       " 0.004811017774045467,\n",
       " 0.0024855290539562702,\n",
       " 0.0023157973773777485,\n",
       " 0.002860597800463438,\n",
       " 0.0028028758242726326,\n",
       " 0.002550694392994046,\n",
       " 0.005869901739060879,\n",
       " 0.0032259183935821056,\n",
       " 0.002659678226336837,\n",
       " 0.002854064805433154,\n",
       " 0.003311916021630168,\n",
       " 0.010740561410784721,\n",
       " 0.00753612257540226,\n",
       " 0.008038284257054329,\n",
       " 0.004397302400320768,\n",
       " 0.00523423170670867,\n",
       " 0.006615928374230862,\n",
       " 0.009857000783085823,\n",
       " 0.0034923276398330927,\n",
       " 0.00295337475836277,\n",
       " 0.005640970077365637,\n",
       " 0.004137564450502396,\n",
       " 0.003532001981511712,\n",
       " 0.0034665598068386316,\n",
       " 0.0019283955916762352,\n",
       " 0.0029882395174354315,\n",
       " 0.0018482654122635722,\n",
       " 0.0038018012419342995,\n",
       " 0.00413721427321434,\n",
       " 0.003460631240159273,\n",
       " 0.004325638525187969,\n",
       " 0.003304300596937537,\n",
       " 0.008198314346373081,\n",
       " 0.0035801122430711985,\n",
       " 0.00960849691182375,\n",
       " 0.007101583294570446,\n",
       " 0.009681358933448792,\n",
       " 0.007227329537272453,\n",
       " 0.00576284434646368,\n",
       " 0.008034825325012207,\n",
       " 0.006401179824024439,\n",
       " 0.013587460853159428,\n",
       " 0.007991648279130459,\n",
       " 0.011342914775013924,\n",
       " 0.0047746263444423676,\n",
       " 0.0061743310652673244,\n",
       " 0.004715310875326395,\n",
       " 0.003133962629362941,\n",
       " 0.0031318673864006996,\n",
       " 0.0035826661624014378,\n",
       " 0.0058870986104011536,\n",
       " 0.001983908237889409,\n",
       " 0.001769079826772213,\n",
       " 0.0030368687584996223,\n",
       " 0.0037880376912653446,\n",
       " 0.004154295660555363,\n",
       " 0.0026539606042206287,\n",
       " 0.002243938622996211,\n",
       " 0.002993845148012042,\n",
       " 0.0020949358586221933,\n",
       " 0.002645893720909953,\n",
       " 0.0058737643994390965,\n",
       " 0.004516084678471088,\n",
       " 0.016969425603747368,\n",
       " 0.02306835725903511,\n",
       " 0.022580169141292572,\n",
       " 0.010876518674194813,\n",
       " 0.006568704731762409,\n",
       " 0.00701990257948637,\n",
       " 0.006086360197514296,\n",
       " 0.009149388410151005,\n",
       " 0.004428587853908539,\n",
       " 0.013482166454195976,\n",
       " 0.01594129204750061,\n",
       " 0.020472366362810135,\n",
       " 0.008525590412318707,\n",
       " 0.008548887446522713,\n",
       " 0.006468703970313072,\n",
       " 0.012538455426692963,\n",
       " 0.007172508630901575,\n",
       " 0.007496543228626251,\n",
       " 0.004712446592748165,\n",
       " 0.005942116491496563,\n",
       " 0.004492943175137043,\n",
       " 0.004471838008612394,\n",
       " 0.014182615093886852,\n",
       " 0.010427954606711864,\n",
       " 0.016916902735829353,\n",
       " 0.007515300996601582,\n",
       " 0.0052055674605071545,\n",
       " 0.005758700892329216,\n",
       " 0.0024446099996566772,\n",
       " 0.003945369739085436,\n",
       " 0.005568331573158503,\n",
       " 0.006153006572276354,\n",
       " 0.0030070992652326822,\n",
       " 0.006425025407224894,\n",
       " 0.005266859196126461,\n",
       " 0.003543631639331579,\n",
       " 0.003931217826902866,\n",
       " 0.002438953844830394,\n",
       " 0.004528061952441931,\n",
       " 0.003046193392947316,\n",
       " 0.003941905219107866,\n",
       " 0.0028377415146678686,\n",
       " 0.0026115053333342075,\n",
       " 0.00258357054553926,\n",
       " 0.00196280749514699,\n",
       " 0.004466932266950607,\n",
       " 0.0033111535012722015,\n",
       " 0.0023371411953121424,\n",
       " 0.003509670961648226,\n",
       " 0.004248518962413073,\n",
       " 0.005226029548794031,\n",
       " 0.002192443935200572,\n",
       " 0.0035093086771667004,\n",
       " 0.002450429368764162,\n",
       " 0.0018998017767444253,\n",
       " 0.0016159090446308255,\n",
       " 0.0029914849437773228,\n",
       " 0.0017432235181331635,\n",
       " 0.0013177351793274283,\n",
       " 0.010362273082137108,\n",
       " 0.00956591498106718,\n",
       " 0.012432226911187172,\n",
       " 0.004061474464833736,\n",
       " 0.004652098752558231,\n",
       " 0.002451174659654498,\n",
       " 0.004499433096498251,\n",
       " 0.0024358078371733427,\n",
       " 0.0012064754264429212,\n",
       " 0.0016566970152780414,\n",
       " 0.004670131951570511,\n",
       " 0.00296039623208344,\n",
       " 0.0031364953611046076,\n",
       " 0.002689814195036888,\n",
       " 0.007412025239318609,\n",
       " 0.009020515717566013,\n",
       " 0.0062100267969071865,\n",
       " 0.004907664377242327,\n",
       " 0.0030647164676338434,\n",
       " 0.010990972630679607,\n",
       " 0.019115598872303963,\n",
       " 0.010206273756921291,\n",
       " 0.01662386581301689,\n",
       " 0.020527586340904236,\n",
       " 0.03622007742524147,\n",
       " 0.01240365020930767,\n",
       " 0.010397577658295631,\n",
       " 0.015362345613539219,\n",
       " 0.00986861065030098,\n",
       " 0.025265157222747803,\n",
       " 0.023592306300997734,\n",
       " 0.008678914047777653,\n",
       " 0.012622155249118805,\n",
       " 0.007838395424187183,\n",
       " 0.006235823966562748,\n",
       " 0.0038977377116680145,\n",
       " 0.006863719783723354,\n",
       " 0.005620995536446571,\n",
       " 0.01256273128092289,\n",
       " 0.009260362945497036,\n",
       " 0.005425449926406145,\n",
       " 0.005809431429952383,\n",
       " 0.0048726629465818405,\n",
       " 0.015342893078923225,\n",
       " 0.011025168001651764,\n",
       " 0.00795227661728859,\n",
       " 0.005075177177786827,\n",
       " 0.004681427963078022,\n",
       " 0.0048743486404418945,\n",
       " 0.005592408590018749,\n",
       " 0.005110078491270542,\n",
       " 0.0029564471915364265,\n",
       " 0.0029358433093875647,\n",
       " 0.0034734494984149933,\n",
       " 0.0020136607345193624,\n",
       " 0.0021551314275711775,\n",
       " 0.005276263691484928,\n",
       " 0.00214749644510448,\n",
       " 0.0023958447854965925,\n",
       " 0.0022012819536030293,\n",
       " 0.0021274141035974026,\n",
       " 0.002012405777350068,\n",
       " 0.0028067196253687143,\n",
       " 0.0023788572289049625,\n",
       " 0.0028454295825213194,\n",
       " 0.004883314948529005,\n",
       " 0.0043621910735964775,\n",
       " 0.002756798639893532,\n",
       " 0.0022670694161206484,\n",
       " 0.006446437444537878,\n",
       " 0.004757666494697332,\n",
       " 0.0035251465160399675,\n",
       " 0.0031734169460833073,\n",
       " 0.002517345594242215,\n",
       " 0.007137947250157595,\n",
       " 0.0052109891548752785,\n",
       " 0.005412143189460039,\n",
       " 0.00888020172715187,\n",
       " 0.003142684232443571,\n",
       " 0.00408776244148612,\n",
       " 0.012039954774081707,\n",
       " 0.008427237160503864,\n",
       " 0.00672127353027463,\n",
       " 0.003765490371733904,\n",
       " 0.006475062109529972,\n",
       " 0.003647231962531805,\n",
       " 0.006283697206526995,\n",
       " 0.0067507424391806126,\n",
       " 0.006054211407899857,\n",
       " 0.0036810620222240686,\n",
       " 0.0032676993869245052,\n",
       " 0.0024662320502102375,\n",
       " 0.0019844784401357174,\n",
       " 0.003338300157338381,\n",
       " 0.004832656122744083,\n",
       " 0.005726789589971304,\n",
       " 0.004753267392516136,\n",
       " 0.002652921713888645,\n",
       " 0.0036793469917029142,\n",
       " 0.0029450233560055494,\n",
       " 0.001795386429876089,\n",
       " 0.0029049310833215714,\n",
       " 0.0058993068523705006,\n",
       " 0.0073335240595042706]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd8e3db-6fca-4406-a406-8ba843f82d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 319\n",
      "Best RMSE: 0.11332903873438674\n"
     ]
    }
   ],
   "source": [
    "root_mean_squared_error = np.sqrt(result.history['mean_squared_error'])\n",
    "val_root_mean_squared_error = np.sqrt(result.history['val_mean_squared_error'])\n",
    "\n",
    "best_epoch = list (val_root_mean_squared_error).index(min(val_root_mean_squared_error)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n",
    "print (f'Best RMSE: {min(val_root_mean_squared_error)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d0c731a-b4d1-4d76-98ae-65add3a12100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20f329f0d00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(history.history['loss'], color='red', linestyle='--')\n",
    "ax1.plot(history.history['val_loss'], color='green', linestyle='--')\n",
    "plt.title('model performance')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train loss', 'val loss', 'train RMSE', 'varl RMSE'], loc='upper left')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax2.plot(root_mean_squared_error)\n",
    "ax2.plot(val_root_mean_squared_error)\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.legend(['train RMSE', 'val RMSE'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ac7a0f4-f348-4e11-a5ba-e3a593fef68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy\n",
    "model.load_weights('model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97c9546b-6b37-4187-94b7-d48f1e7547b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test RMSE: 0.11858616070217773\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Print test RMSE\n",
    "print('\\n', 'Test RMSE:', np.sqrt(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f52240-f93b-4a1a-bbe5-d5440d2f274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'mean_squared_error']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e49fe58c-a375-4465-8d95-d6ecc8f3b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat = y_hat.reshape(y_hat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f2abe3f-86e4-4448-abef-52327160fba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([172, 252, 288, 259,  94,  71,  38,  97,   8,  99, 109, 286,   7,\n",
       "       230, 197])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_vals=np.random.choice(X_test.shape[0], size=15, replace=False)\n",
    "rand_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09dde420-61ee-415b-b92b-8f0dfd881b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172: predict=11.879438400268555 / true=11.849404844423074\n",
      "252: predict=11.892304420471191 / true=11.849404844423074\n",
      "288: predict=12.400896072387695 / true=12.373707715234994\n",
      "259: predict=12.281092643737793 / true=12.445093483000798\n",
      "94: predict=11.82100772857666 / true=11.695255355062795\n",
      "71: predict=11.888033866882324 / true=11.904974309480183\n",
      "38: predict=12.204192161560059 / true=12.242891437918386\n",
      "97: predict=12.555480003356934 / true=12.631343648903034\n",
      "8: predict=11.76099681854248 / true=11.715874472198905\n",
      "99: predict=11.938748359680176 / true=11.964007453736912\n",
      "109: predict=11.88321590423584 / true=11.97603664577121\n",
      "286: predict=11.662081718444824 / true=11.608244735642321\n",
      "7: predict=11.3983736038208 / true=11.302216779257382\n",
      "230: predict=12.008323669433594 / true=12.128116509451258\n",
      "197: predict=12.806427955627441 / true=12.75130259456002\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(rand_vals):\n",
    "    predict_index = y_hat[index]\n",
    "    true_index = y_test.to_numpy()[index]\n",
    "    print (f'{index}: predict={predict_index} / true={true_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8dbcb93-1524-49cf-8490-a0611cd5cfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20f34abce50>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "plt.title('Prediction Delta')\n",
    "plt.ylabel('Delta')\n",
    "plt.xlabel('Index')\n",
    "ax1.plot(np.subtract(y_test.to_numpy(),y_hat), color='red', linestyle='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab4b03f-bb03-4b41-98be-8ab521da1b4d",
   "metadata": {},
   "source": [
    "# Weitere Optimierungsmglichkeiten\n",
    "## GPU Support\n",
    "\n",
    "https://lifewithdata.com/2022/01/16/how-to-install-tensorflow-and-keras-with-gpu-support-on-windows/\n",
    "\n",
    "## Anregungen zur Hyperparameter-Suche\n",
    "\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "## Keras Tuner Dokumentation\n",
    "\n",
    "https://keras.io/api/keras_tuner/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86dd787-043a-4686-a688-7e39000d1b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
