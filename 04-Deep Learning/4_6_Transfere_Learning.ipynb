{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "632d9eec29bb5b32",
   "metadata": {},
   "source": [
    "Credits to https://keras.io/guides/transfer_learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2885ff1aae2617",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:02:05.530761Z",
     "start_time": "2024-04-12T09:02:02.707403Z"
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow_datasets as tfds\n",
    "from keras.utils import image_dataset_from_directory, split_dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.layers import RandomFlip, RandomRotation\n",
    "from tensorflow import data as tf_data\n",
    "from  keras.applications import Xception\n",
    "from keras import Input\n",
    "from keras.layers import Rescaling\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "seed = 4512\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "warnings.warn_explicit = ignore_warn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632995d4d1779ea3",
   "metadata": {},
   "source": [
    "# Load data from local folder\n",
    "You need to load and expand data from  https://www.kaggle.com/c/dogs-vs-cats/data?select=train.zip\n",
    "\n",
    "After downloading follow these steps:\n",
    "* Expand data to Folder studientage-ml/data/cats_dogs\n",
    "* create two folders \"cats\" and \"dogs\":\n",
    "* studientage-ml/data/cats_dogs/cats\n",
    "* studientage-ml/data/cats_dogs/dogs\n",
    "* move all cats<no>.jpg images to the \"cats\" folder and all dogs<no>.jpg images to the \"dogs\" folde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5483970adc4aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:03:23.764087Z",
     "start_time": "2024-04-12T09:03:21.336444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data; 80% training; 20% for validation and test (see below)\n",
    "train_ds, test = image_dataset_from_directory(\n",
    "    \"../data/cats_dogs\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=None,\n",
    "    image_size=(150, 150),\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdafec5a1c16e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:03:27.188152Z",
     "start_time": "2024-04-12T09:03:25.043661Z"
    }
   },
   "outputs": [],
   "source": [
    "# make sure we have 10% validation and 10% test data\n",
    "validation_ds, test_ds = split_dataset(test, left_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6964a835c3af0afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:03:29.624550Z",
     "start_time": "2024-04-12T09:03:28.197368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show some sample images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image/255)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efafc1119bf7e81",
   "metadata": {},
   "source": [
    "# Using random data augmentation\n",
    "When you don't have a large image dataset, it's a good practice to artificially introduce sample diversity by applying random yet realistic transformations to the training images, such as random horizontal flipping or small random rotations. This helps expose the model to different aspects of the training data while slowing down overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d47443e2d55e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:21:17.316761Z",
     "start_time": "2024-04-12T09:21:17.066401Z"
    }
   },
   "outputs": [],
   "source": [
    "augmentation_layers = [\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "def data_augmentation(x):\n",
    "    for layer in augmentation_layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260dc04aca2836c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:21:20.739550Z",
     "start_time": "2024-04-12T09:21:19.366746Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image/255)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b343eeba37d6efc6",
   "metadata": {},
   "source": [
    "# show augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f517925c58112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:21:36.633741Z",
     "start_time": "2024-04-12T09:21:27.041196Z"
    }
   },
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = images\n",
    "    print (labels)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(np.expand_dims(first_image, 0))\n",
    "        plt.imshow(np.array(augmented_image[0]).astype(\"int32\"))\n",
    "        plt.title(int(labels))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c2b14029291f8",
   "metadata": {},
   "source": [
    "# Configure batch prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb09d2a5220373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:22:08.657650Z",
     "start_time": "2024-04-12T09:22:08.626876Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n",
    "validation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()\n",
    "test_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33872fd96f33e77",
   "metadata": {},
   "source": [
    "# Build a model\n",
    "Now let's built a model that follows the blueprint we've explained earlier.\n",
    "\n",
    "Note that:\n",
    "\n",
    "* We add a Rescaling layer to scale input values (initially in the [0, 255] range) to the [-1, 1] range.\n",
    "* We add a Dropout layer before the classification layer, for regularization.\n",
    "* We make sure to pass training=False when calling the base model, so that it runs in inference mode, so that batchnorm statistics don't get updated even after we unfreeze the base model for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847a11aba693433d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:22:20.429108Z",
     "start_time": "2024-04-12T09:22:18.022170Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = Xception(\n",
    "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    ")  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "# Create new model on top\n",
    "inputs = Input(shape=(150, 150, 3))\n",
    "\n",
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "scale_layer = Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(inputs)\n",
    "\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x)  # Regularize with dropout\n",
    "outputs = Dense(1)(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18be8ca43398326a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:24:16.356006Z",
     "start_time": "2024-04-12T09:24:16.325359Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.metrics import BinaryAccuracy\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[BinaryAccuracy()],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eec5af-726b-464f-9d75-4b8f31980496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T17:37:02.374492Z",
     "start_time": "2024-04-11T17:28:34.003254Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "print(\"Fitting the top layer of the model\")\n",
    "result = model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a6750e-46db-4703-9470-328f7cc93dc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T17:37:30.565902Z",
     "start_time": "2024-04-11T17:37:02.374492Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Test dataset evaluation\")\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733622a7-9b35-4378-aaaa-a1fe55220b38",
   "metadata": {},
   "source": [
    "# Do a round of fine-tuning of the entire model\n",
    "Finally, let's unfreeze the base model and train the entire model end-to-end with a low learning rate.\n",
    "\n",
    "Importantly, although the base model becomes trainable, it is still running in inference mode since we passed training=False when calling it when we built the model. This means that the batch normalization layers inside won't update their batch statistics. If they did, they would wreck havoc on the representations learned by the model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51518a8-9a15-4366-9c61-7095d6cba01e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T17:58:09.394442Z",
     "start_time": "2024-04-11T17:58:09.316307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary(show_trainable=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-5),  # Low learning rate\n",
    "    loss=BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[BinaryAccuracy()],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838253aa-aa74-46af-9352-ecb0e5864bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T18:12:11.121974Z",
     "start_time": "2024-04-11T17:58:37.949633Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "epochs = 1\n",
    "print(\"Fitting the end-to-end model\")\n",
    "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5541a365-fbf1-4b68-82b2-464bdc058f31",
   "metadata": {},
   "source": [
    "After 10 (tbd.) epochs, fine-tuning gains us a nice improvement here. Let's evaluate the model on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f0ea9-cf54-4238-beb2-df4663ade084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T18:12:36.955440Z",
     "start_time": "2024-04-11T18:12:11.121974Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Test dataset evaluation\")\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cded19d-8688-492e-8e6c-87bb84d3bd37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:34:41.107726Z",
     "start_time": "2024-04-12T09:34:41.092108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Idee: BeispielBild laden und predicten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01f565f98d4b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
